{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_loaders import load_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data contains 17 topics and 264 subtopics\n"
     ]
    }
   ],
   "source": [
    "# Description: Load tsv file\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "# Load tsv file\n",
    "News = pd.read_csv('MINDsmall_train/news.tsv', sep='\\t', header=None)\n",
    "News.columns = ['news_id', 'category', 'subcategory', 'title', 'abstract', 'url', 'title_entities', 'abstract_entities']\n",
    "News_vali = pd.read_csv('MINDsmall_dev/news.tsv', sep='\\t', header=None)\n",
    "News_vali.columns = ['news_id', 'category', 'subcategory', 'title', 'abstract', 'url', 'title_entities', 'abstract_entities']\n",
    "\n",
    "News = pd.concat([News, News_vali], ignore_index=True)\n",
    "\n",
    "\n",
    "UserData = pd.read_csv('MINDsmall_train/behaviors.tsv', sep='\\t', header=None)\n",
    "UserData.columns = ['impression_id', 'user_id', 'time', 'history', 'impressions']\n",
    "\n",
    "UserData = UserData.dropna()\n",
    "\n",
    "topic_size = News['category'].nunique()\n",
    "subtopic_size = News['subcategory'].nunique()\n",
    "\n",
    "print(f\"Data contains {topic_size} topics and {subtopic_size} subtopics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikolaj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted tensor([3, 2, 4, 2, 1, 0, 3, 1, 4, 0], device='cuda:0') with loss 12.576431274414062\n",
      "Predicted tensor([3, 2, 4, 2, 1, 0, 2, 1, 4, 0], device='cuda:0') with loss 9.68658447265625\n",
      "Predicted tensor([1, 2, 4, 2, 1, 2, 1, 1, 3, 0], device='cuda:0') with loss 8.20469856262207\n",
      "Predicted tensor([4, 2, 4, 4, 1, 2, 3, 1, 3, 0], device='cuda:0') with loss 7.97101354598999\n",
      "Predicted tensor([0, 0, 4, 0, 1, 0, 3, 1, 3, 0], device='cuda:0') with loss 5.2576422691345215\n",
      "Predicted tensor([1, 2, 4, 0, 2, 0, 3, 1, 3, 0], device='cuda:0') with loss 3.297945499420166\n",
      "Predicted tensor([1, 0, 4, 0, 2, 0, 3, 0, 1, 0], device='cuda:0') with loss 1.1414740085601807\n",
      "Predicted tensor([1, 0, 4, 0, 2, 0, 3, 2, 1, 0], device='cuda:0') with loss 1.9333064556121826\n",
      "Predicted tensor([1, 0, 4, 0, 2, 0, 3, 0, 1, 2], device='cuda:0') with loss 0.02471764385700226\n",
      "Predicted tensor([1, 0, 4, 0, 2, 0, 3, 0, 1, 2], device='cuda:0') with loss 0.025607779622077942\n",
      "Predicted tensor([0, 0, 4, 0, 2, 0, 3, 0, 2, 0], device='cuda:0') with loss 0.9237348437309265\n",
      "Predicted tensor([1, 0, 4, 0, 2, 0, 3, 0, 1, 2], device='cuda:0') with loss 0.04172644764184952\n",
      "Predicted tensor([1, 0, 4, 0, 2, 0, 3, 0, 1, 2], device='cuda:0') with loss 0.003988094162195921\n",
      "Predicted tensor([1, 0, 4, 0, 2, 3, 3, 0, 1, 2], device='cuda:0') with loss 0.20720167458057404\n",
      "Predicted tensor([1, 0, 4, 0, 2, 0, 3, 0, 1, 2], device='cuda:0') with loss 0.00023724709171801805\n"
     ]
    }
   ],
   "source": [
    "# Define Vocabulary for users and topics\n",
    "from torchtext import vocab\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import torch as th\n",
    "from LSTUR import GloVe\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "User_vocab = vocab.build_vocab_from_iterator([[id] for id in UserData['user_id']])\n",
    "News_vocab = vocab.build_vocab_from_iterator([[id] for id in  News['news_id']])\n",
    "Category_vocab = vocab.build_vocab_from_iterator([[Category] for Category in News['category']])\n",
    "Subcategory_vocab = vocab.build_vocab_from_iterator([[Category] for Category in News['subcategory']])\n",
    "\n",
    "# Define Vocabulary for title and abstract\n",
    "max_title_length = max([len(tokenizer(title)) for title in News['title']])\n",
    "max_history_length = max([len(history.split(\" \")) for history in UserData['history']])\n",
    "max_history_length = 50 # Overwrite\n",
    "\n",
    "max_impressions_length = max([len(impressions.split(\" \")) for impressions in UserData['impressions']])\n",
    "max_impressions_length = 5 # Overwrite\n",
    "\n",
    "# Define Datapoint to tensor\n",
    "def Datapoint_to_Encodings(User):\n",
    "\n",
    "    History = News_vocab.lookup_indices(User.history.split(\" \"))\n",
    "    User_en = User_vocab.__getitem__(User.user_id)\n",
    "    Impressions = User.impressions.split(\" \")\n",
    "    Impressions,Clicked = map(list, zip(*[Impression.split(\"-\") for Impression in Impressions]))\n",
    "    \n",
    "    Positive, Negative = [],[]\n",
    "    for idx, click in enumerate(Clicked):\n",
    "        if click == \"1\":\n",
    "            Positive.append(Impressions[idx])\n",
    "        else:\n",
    "            Negative.append(Impressions[idx])\n",
    "\n",
    "    Impressions = [Positive[0]]\n",
    "\n",
    "   \n",
    "\n",
    "    if len(Negative) > 3:\n",
    "        for _ in random.sample(Negative,4):\n",
    "            Impressions.append(_)\n",
    "    else:\n",
    "        for _ in range(4):\n",
    "            Impressions.append(random.choice(Negative))\n",
    "\n",
    "    Clicked = [1,0,0,0,0]\n",
    "\n",
    "    # Shuffle\n",
    "    shuffled_index = [0,1,2,3,4]\n",
    "    random.shuffle(shuffled_index)\n",
    "\n",
    "\n",
    "    Impressions = [Impressions[i] for i in shuffled_index]\n",
    "    Clicked = [Clicked[i] for i in shuffled_index]\n",
    "\n",
    "\n",
    "    # Convert to tensor\n",
    "    Impressions = News_vocab.lookup_indices(Impressions)\n",
    "    History, User_en, Impressions, Clicked = map(th.tensor, [History, User_en, Impressions, Clicked])\n",
    "\n",
    "    return History, User_en, Impressions, Clicked\n",
    "\n",
    "# Pack Title\n",
    "def pack_Title(title,max_length):\n",
    "\n",
    "    src_len, _ = title.size()\n",
    "\n",
    "    title_reformated = th.zeros(max_length,300)\n",
    "\n",
    "    title_reformated[:src_len,:] = title\n",
    "\n",
    "    return title_reformated, src_len\n",
    "\n",
    "\n",
    "# Get Numeric Artikles representation\n",
    "def get_Article_Encodings(Artikle):\n",
    "\n",
    "\n",
    "    title = GloVe.get_vecs_by_tokens(tokenizer(Artikle['title']))\n",
    "    \n",
    "    #Abstract = [tokenizer(abstract) for abstract in Artikle['abstract']]\n",
    "    Category = Category_vocab.__getitem__(Artikle['category'])\n",
    "    Subcategory = Subcategory_vocab.__getitem__(Artikle['subcategory'])\n",
    "\n",
    "    title, title_len = pack_Title(title,max_title_length)\n",
    "\n",
    "    Category, Subcategory, title_len = map(th.tensor, [Category, Subcategory, title_len])\n",
    "\n",
    "    \n",
    "\n",
    "    return Category, Subcategory, title, title_len\n",
    "\n",
    "# Store all News in Dictionary for faster access\n",
    "News_tensors = {}\n",
    "\n",
    "for i in range(len(News)):\n",
    "    News_tensors[News_vocab.__getitem__(News['news_id'][i])] = get_Article_Encodings(News.loc[i])\n",
    "\n",
    "# Get Numeric User representation\n",
    "def Datapoint_to_tensor(User):\n",
    "\n",
    "    History, User_en, Impressions, Clicked = Datapoint_to_Encodings(User)\n",
    "\n",
    "    History_tensor = th.zeros(max_history_length,max_title_length,300)\n",
    "    Category = th.zeros(max_history_length)\n",
    "    Subcategory = th.zeros(max_history_length)\n",
    "    history_len = min(len(History),max_history_length)\n",
    "\n",
    "    for idx,article in enumerate(History[-history_len:]):\n",
    "        Category[idx], Subcategory[idx], History_tensor[idx], _ = News_tensors[article.item()]\n",
    "\n",
    "    Impressions_tensor = th.zeros(max_impressions_length,max_title_length,300)\n",
    "    Category_Impressions = th.zeros(max_impressions_length)\n",
    "    Subcategory_Impressions = th.zeros(max_impressions_length)\n",
    "    Impressions_len = len(Impressions)\n",
    "\n",
    "    history_len, Impressions_len = map(th.tensor, [history_len, Impressions_len])\n",
    "\n",
    "\n",
    "    for idx,article in enumerate(Impressions):\n",
    "        Category_Impressions[idx], Subcategory_Impressions[idx], Impressions_tensor[idx], _ = News_tensors[article.item()]\n",
    "    \n",
    "    Clicked = Clicked.argmax()\n",
    "\n",
    "    return User_en, Category, Subcategory, History_tensor, history_len, Category_Impressions, Subcategory_Impressions, Impressions_tensor, Impressions_len, Clicked\n",
    "\n",
    "\n",
    "# Def load batch\n",
    "def load_batch(User, batch_size, device='cpu'):\n",
    "    \n",
    "        # User = User.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "        for i in range(0, len(User), batch_size):\n",
    "    \n",
    "            User_batch = User[i:i+batch_size]\n",
    "    \n",
    "            User_en = []\n",
    "            Category = []\n",
    "            Subcategory = []\n",
    "            History_tensor = []\n",
    "            history_len = []\n",
    "            Category_Impressions = []\n",
    "            Subcategory_Impressions = []\n",
    "            Impressions_tensor = []\n",
    "            Impressions_len = []\n",
    "            Clicked = []\n",
    "    \n",
    "            for i in range(len(User_batch)):\n",
    "                User_en_, Category_, Subcategory_, History_tensor_, history_len_, Category_Impressions_, Subcategory_Impressions_, Impressions_tensor_, Impressions_len_, Clicked_ = Datapoint_to_tensor(User_batch.iloc[i])\n",
    "                User_en.append(User_en_)\n",
    "                Category.append(Category_)\n",
    "                Subcategory.append(Subcategory_)\n",
    "                History_tensor.append(History_tensor_)\n",
    "                history_len.append(history_len_)\n",
    "                Category_Impressions.append(Category_Impressions_)\n",
    "                Subcategory_Impressions.append(Subcategory_Impressions_)\n",
    "                Impressions_tensor.append(Impressions_tensor_)\n",
    "                Impressions_len.append(Impressions_len_)\n",
    "                Clicked.append(Clicked_)\n",
    "    \n",
    "            User_en, Category, Subcategory, History_tensor, history_len, Category_Impressions, Subcategory_Impressions, Impressions_tensor, Impressions_len, Clicked = map(th.stack, [User_en, Category, Subcategory, History_tensor, history_len, Category_Impressions, Subcategory_Impressions, Impressions_tensor, Impressions_len, Clicked])\n",
    "            User_en, Category, Subcategory, history_len, Category_Impressions, Subcategory_Impressions, Impressions_len, Clicked = map(lambda x: x.long(), [User_en, Category, Subcategory, history_len, Category_Impressions, Subcategory_Impressions, Impressions_len, Clicked])\n",
    "            yield User_en.to(device), Category.to(device), Subcategory.to(device), History_tensor.to(device), history_len.to(device), Category_Impressions.to(device), Subcategory_Impressions.to(device), Impressions_tensor.to(device), Impressions_len.to(device), Clicked.to(device)\n",
    "\n",
    "            #yield User_en, Category, Subcategory, History_tensor, history_len, Category_Impressions, Subcategory_Impressions, Impressions_tensor, Impressions_len, Clicked\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "History_lengths = th.tensor([len(history.split(\" \")) for history in UserData['history']])\n",
    "Impressions_length = th.tensor([len(impressions.split(\" \")) for impressions in UserData['impressions']])\n",
    "UserData['History Length'] = History_lengths\n",
    "UserData['Impressions Length'] = Impressions_length\n",
    "\n",
    "User_low = UserData[UserData['History Length'] < 51].copy()\n",
    "\n",
    "User_low = User_low.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "from LSTUR import LSTUR_con\n",
    "from torch import nn,optim\n",
    "device = \"cuda\"\n",
    "\n",
    "LSTUR_con_module = LSTUR_con(\n",
    "    seq_len = max_history_length,\n",
    "    user_dim=300,\n",
    "    user_size=User_vocab.__len__(),\n",
    "    topic_size=Category_vocab.__len__(),\n",
    "    topic_dim=100,\n",
    "    subtopic_size=Subcategory_vocab.__len__(),\n",
    "    subtopic_dim=100,\n",
    "    word_dim=300,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(LSTUR_con_module.parameters(), lr=0.001)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9, 50, 16, 10,  4, 36, 35,  4, 19, 28, 50, 50, 50, 50, 50, 39, 25, 10,\n",
      "         5, 40, 50, 50, 50, 50, 12, 20, 38, 20, 12, 50,  3, 10, 18, 50, 26, 50,\n",
      "         9, 14, 50,  3, 32, 50, 19,  6,  9, 12, 22, 17, 50, 35, 27, 11, 38, 11,\n",
      "        26, 19, 40, 50, 13, 31, 18, 50, 13,  2,  9, 40, 37, 31, 50, 15, 30, 25,\n",
      "         9, 45, 15, 11, 50,  8,  4, 50, 14, 22, 12,  8,  4, 20, 41, 43,  1, 46,\n",
      "        18,  5, 50,  3, 39, 20, 50, 33, 20,  3], device='cuda:0')\n",
      "tensor(5.7061, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "BatchSize = 100\n",
    "\n",
    "model = LSTUR_con_module.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "for epoch in range(5):\n",
    "\n",
    "    BatchLoader = load_batch(UserData, batch_size=BatchSize,device=device)\n",
    "\n",
    "    for _ in range(50):\n",
    "        User_en, Category, Subcategory, History_tensor, history_len, Category_Impressions, Subcategory_Impressions, Impressions_tensor, Impressions_len, Clicked = BatchLoader.__next__()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(User_en, Category, Subcategory, History_tensor, history_len, Category_Impressions, Subcategory_Impressions, Impressions_tensor)\n",
    "\n",
    "        loss = loss_fn(output, Clicked)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.save(model, \"lstur.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\nRuntimeError: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"<string>\", line 47, in <forward op>\n            p1m = (1. - p) * float(train)\n            scale = 1. / (float(p1m == 0.) + p1m)\n            res,mask = torch.native_dropout(input, p, train)\n                       ~~~~~~~~~~~~~~~~~~~~ <--- HERE\n\n            def backward(grad_output):\nRuntimeError: The operator 'aten::native_dropout' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m my_scripted_model \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mscript(LSTUR_con_module)\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n\u001b[0;32m---> 22\u001b[0m     out \u001b[39m=\u001b[39m my_scripted_model(\n\u001b[1;32m     23\u001b[0m         User_en\u001b[39m.\u001b[39;49mlong(),\n\u001b[1;32m     24\u001b[0m         Category\u001b[39m.\u001b[39;49mlong(),\n\u001b[1;32m     25\u001b[0m         Subcategory\u001b[39m.\u001b[39;49mlong(),\n\u001b[1;32m     26\u001b[0m         History_tensor,\n\u001b[1;32m     27\u001b[0m         history_len\u001b[39m.\u001b[39;49mlong(),\n\u001b[1;32m     28\u001b[0m         Category_Impressions\u001b[39m.\u001b[39;49mlong(),\n\u001b[1;32m     29\u001b[0m         Subcategory_Impressions\u001b[39m.\u001b[39;49mlong(),\n\u001b[1;32m     30\u001b[0m         Impressions_tensor, \n\u001b[1;32m     31\u001b[0m     )\n\u001b[1;32m     33\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(out, Clicked\u001b[39m.\u001b[39mlong())\n\u001b[1;32m     35\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/Documents/UNI-DTU/6. Semester/Bachelor Projekt/News-Recommendations/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\nRuntimeError: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"<string>\", line 47, in <forward op>\n            p1m = (1. - p) * float(train)\n            scale = 1. / (float(p1m == 0.) + p1m)\n            res,mask = torch.native_dropout(input, p, train)\n                       ~~~~~~~~~~~~~~~~~~~~ <--- HERE\n\n            def backward(grad_output):\nRuntimeError: The operator 'aten::native_dropout' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.\n\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "from LSTUR import LSTUR_con\n",
    "from torch import nn,optim\n",
    "\n",
    "LSTUR_con_module = LSTUR_con(\n",
    "    seq_len = max_history_length,\n",
    "    user_dim=300,\n",
    "    user_size=User_vocab.__len__(),\n",
    "    topic_size=Category_vocab.__len__(),\n",
    "    topic_dim=100,\n",
    "    subtopic_size=Subcategory_vocab.__len__(),\n",
    "    subtopic_dim=100,\n",
    "    word_dim=300\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(LSTUR_con_module.parameters(), lr=0.001)\n",
    "\n",
    "my_scripted_model = th.jit.script(LSTUR_con_module).to('mps')\n",
    "\n",
    "for i in range(5):\n",
    "    out = my_scripted_model(\n",
    "        User_en.long(),\n",
    "        Category.long(),\n",
    "        Subcategory.long(),\n",
    "        History_tensor,\n",
    "        history_len.long(),\n",
    "        Category_Impressions.long(),\n",
    "        Subcategory_Impressions.long(),\n",
    "        Impressions_tensor, \n",
    "    )\n",
    "\n",
    "    loss = loss_fn(out, Clicked.long())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(loss)\n",
    "    print(out.argmax(dim=1))\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 4, 1, 2, 0, 0, 1, 3, 0])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Clicked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 11, 12]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "len(test)\n",
    "\n",
    "test[-3:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0099, grad_fn=<NllLossBackward0>)\n",
      "tensor([ 5, 27,  5, 14,  0])\n",
      "\n",
      "tensor(0.0023, grad_fn=<NllLossBackward0>)\n",
      "tensor([ 5, 27,  5, 14,  0])\n",
      "\n",
      "tensor(0.0022, grad_fn=<NllLossBackward0>)\n",
      "tensor([ 5, 27,  5, 14,  0])\n",
      "\n",
      "tensor(0.0008, grad_fn=<NllLossBackward0>)\n",
      "tensor([ 5, 27,  5, 14,  0])\n",
      "\n",
      "tensor(0.0262, grad_fn=<NllLossBackward0>)\n",
      "tensor([ 5, 27,  5, 14,  0])\n",
      "\n",
      "tensor(0.1536, grad_fn=<NllLossBackward0>)\n",
      "tensor([ 5, 27,  5, 14,  0])\n",
      "\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n",
      "tensor([ 5, 27,  5, 14,  0])\n",
      "\n",
      "tensor(0.0050, grad_fn=<NllLossBackward0>)\n",
      "tensor([ 5, 27,  5, 14,  0])\n",
      "\n",
      "tensor(0.0052, grad_fn=<NllLossBackward0>)\n",
      "tensor([ 5, 27,  5, 14,  0])\n",
      "\n",
      "tensor(0.0159, grad_fn=<NllLossBackward0>)\n",
      "tensor([ 5, 27,  5, 14,  0])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    out = LSTUR_con_module(\n",
    "        User_en.long(),\n",
    "        Category.long(),\n",
    "        Subcategory.long(),\n",
    "        History_tensor,\n",
    "        history_len.long(),\n",
    "        Category_Impressions.long(),\n",
    "        Subcategory_Impressions.long(),\n",
    "        Impressions_tensor, \n",
    "    )\n",
    "\n",
    "    loss = loss_fn(out, Clicked.long())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(loss)\n",
    "    print(out.argmax(dim=1))\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 27,  5, 14,  0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Clicked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikolaj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from LSTUR import NewsEncoder, TitleEncoder, TopicEncoder, GloVe\n",
    "import torch as th\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "topic_embedding_dim = 100\n",
    "subtopic_embedding_dim = 100\n",
    "word_size = 100\n",
    "\n",
    "\n",
    "NewsEncoderModule = NewsEncoder(100, 100, topic_size, subtopic_size, 10000)\n",
    "TitleEncoderModule = TitleEncoder(100)\n",
    "TopicEncoderModule = TopicEncoder(100, 100, topic_size, subtopic_size)\n",
    "\n",
    "topic = th.tensor([0],dtype=th.int32)\n",
    "subtopic = th.tensor([0],dtype=th.int32)\n",
    "\n",
    "title = tokenizer(News['title'][0])\n",
    "W = GloVe.get_vecs_by_tokens(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([51282])\n",
      "torch.Size([51282])\n"
     ]
    }
   ],
   "source": [
    "# Encode categories and subcategories:\n",
    "categories = News['category'].unique()\n",
    "subcategories = News['subcategory'].unique()\n",
    "\n",
    "test = [i for i in range(len(categories))]\n",
    "test2 = [i for i in range(len(subcategories))]\n",
    "\n",
    "# Add encodings to dict\n",
    "res = {}\n",
    "for cat in categories:\n",
    "    for value in test:\n",
    "        res[cat] = value\n",
    "        test.remove(value)\n",
    "        break\n",
    "\n",
    "\n",
    "res2 = {}\n",
    "for subcat in subcategories:\n",
    "    for value in test2:\n",
    "        res2[subcat] = value\n",
    "        test2.remove(value)\n",
    "        break\n",
    "\n",
    "\n",
    "# Replace column with encodings:\n",
    "C = th.tensor(News['category'].replace(res))\n",
    "SC = th.tensor(News['subcategory'].replace(res2))\n",
    "\n",
    "print(C.shape)\n",
    "print(SC.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'brands',\n",
       " 'queen',\n",
       " 'elizabeth',\n",
       " ',',\n",
       " 'prince',\n",
       " 'charles',\n",
       " ',',\n",
       " 'and',\n",
       " 'prince',\n",
       " 'philip',\n",
       " 'swear',\n",
       " 'by']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get titles lengths\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "lengths = th.tensor([len(tokenizer(News['title'][i])) for i in range(News['title'].size)])\n",
    "\n",
    "\n",
    "# Pad titles\n",
    "maxlength = max(lengths)\n",
    "padlengths = (maxlength-lengths).tolist()\n",
    "padtitles = [tokenizer(News[\"title\"][i] + \" <Pad>\"*padlengths[i]) for i in range(len(padlengths))]\n",
    "\n",
    "\n",
    "\n",
    "# Embed titles\n",
    "Article_embedding = th.zeros(len(padtitles),maxlength,300)\n",
    "i = 0\n",
    "for t in padtitles:\n",
    "    Article_embedding[i] = GloVe.get_vecs_by_tokens(t)\n",
    "    i+=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51282\n",
      "torch.Size([64, 300])\n"
     ]
    }
   ],
   "source": [
    "# Dictionary of articles from their ID's\n",
    "newsid = News['news_id']\n",
    "article_dict = {newsid[i]:Article_embedding[i] for i in range(len(padtitles))}\n",
    "\n",
    "print(len(article_dict))\n",
    "print(article_dict[\"N55189\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[127], line 18\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m# Replace column with encodings:\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m U \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mtensor(User[\u001b[39m'\u001b[39;49m\u001b[39muser_id\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mreplace(userid_dict))\n\u001b[0;32m     19\u001b[0m U\u001b[39m.\u001b[39mshape\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\series.py:5380\u001b[0m, in \u001b[0;36mSeries.replace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   5362\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(\n\u001b[0;32m   5363\u001b[0m     version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mto_replace\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   5364\u001b[0m )\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5378\u001b[0m     method: Literal[\u001b[39m\"\u001b[39m\u001b[39mpad\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mffill\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbfill\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m|\u001b[39m lib\u001b[39m.\u001b[39mNoDefault \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mno_default,\n\u001b[0;32m   5379\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 5380\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mreplace(\n\u001b[0;32m   5381\u001b[0m         to_replace\u001b[39m=\u001b[39;49mto_replace,\n\u001b[0;32m   5382\u001b[0m         value\u001b[39m=\u001b[39;49mvalue,\n\u001b[0;32m   5383\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5384\u001b[0m         limit\u001b[39m=\u001b[39;49mlimit,\n\u001b[0;32m   5385\u001b[0m         regex\u001b[39m=\u001b[39;49mregex,\n\u001b[0;32m   5386\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[0;32m   5387\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\generic.py:7188\u001b[0m, in \u001b[0;36mNDFrame.replace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   7185\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   7186\u001b[0m         to_replace, value \u001b[39m=\u001b[39m keys, values\n\u001b[1;32m-> 7188\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreplace(\n\u001b[0;32m   7189\u001b[0m         to_replace, value, inplace\u001b[39m=\u001b[39;49minplace, limit\u001b[39m=\u001b[39;49mlimit, regex\u001b[39m=\u001b[39;49mregex\n\u001b[0;32m   7190\u001b[0m     )\n\u001b[0;32m   7191\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   7192\u001b[0m \n\u001b[0;32m   7193\u001b[0m     \u001b[39m# need a non-zero len on all axes\u001b[39;00m\n\u001b[0;32m   7194\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\series.py:5380\u001b[0m, in \u001b[0;36mSeries.replace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   5362\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(\n\u001b[0;32m   5363\u001b[0m     version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mto_replace\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   5364\u001b[0m )\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5378\u001b[0m     method: Literal[\u001b[39m\"\u001b[39m\u001b[39mpad\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mffill\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbfill\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m|\u001b[39m lib\u001b[39m.\u001b[39mNoDefault \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mno_default,\n\u001b[0;32m   5379\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 5380\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mreplace(\n\u001b[0;32m   5381\u001b[0m         to_replace\u001b[39m=\u001b[39;49mto_replace,\n\u001b[0;32m   5382\u001b[0m         value\u001b[39m=\u001b[39;49mvalue,\n\u001b[0;32m   5383\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5384\u001b[0m         limit\u001b[39m=\u001b[39;49mlimit,\n\u001b[0;32m   5385\u001b[0m         regex\u001b[39m=\u001b[39;49mregex,\n\u001b[0;32m   5386\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[0;32m   5387\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\generic.py:7237\u001b[0m, in \u001b[0;36mNDFrame.replace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   7232\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(to_replace) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(value):\n\u001b[0;32m   7233\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   7234\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReplacement lists must match in length. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   7235\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(to_replace)\u001b[39m}\u001b[39;00m\u001b[39m got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(value)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   7236\u001b[0m         )\n\u001b[1;32m-> 7237\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mreplace_list(\n\u001b[0;32m   7238\u001b[0m         src_list\u001b[39m=\u001b[39;49mto_replace,\n\u001b[0;32m   7239\u001b[0m         dest_list\u001b[39m=\u001b[39;49mvalue,\n\u001b[0;32m   7240\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   7241\u001b[0m         regex\u001b[39m=\u001b[39;49mregex,\n\u001b[0;32m   7242\u001b[0m     )\n\u001b[0;32m   7244\u001b[0m \u001b[39melif\u001b[39;00m to_replace \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   7245\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\n\u001b[0;32m   7246\u001b[0m         is_re_compilable(regex)\n\u001b[0;32m   7247\u001b[0m         \u001b[39mor\u001b[39;00m is_list_like(regex)\n\u001b[0;32m   7248\u001b[0m         \u001b[39mor\u001b[39;00m is_dict_like(regex)\n\u001b[0;32m   7249\u001b[0m     ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\internals\\managers.py:487\u001b[0m, in \u001b[0;36mBaseBlockManager.replace_list\u001b[1;34m(self, src_list, dest_list, inplace, regex)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"do a list replace\"\"\"\u001b[39;00m\n\u001b[0;32m    485\u001b[0m inplace \u001b[39m=\u001b[39m validate_bool_kwarg(inplace, \u001b[39m\"\u001b[39m\u001b[39minplace\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 487\u001b[0m bm \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\n\u001b[0;32m    488\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mreplace_list\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    489\u001b[0m     src_list\u001b[39m=\u001b[39;49msrc_list,\n\u001b[0;32m    490\u001b[0m     dest_list\u001b[39m=\u001b[39;49mdest_list,\n\u001b[0;32m    491\u001b[0m     inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m    492\u001b[0m     regex\u001b[39m=\u001b[39;49mregex,\n\u001b[0;32m    493\u001b[0m )\n\u001b[0;32m    494\u001b[0m bm\u001b[39m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m    495\u001b[0m \u001b[39mreturn\u001b[39;00m bm\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(b, f)(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n\u001b[0;32m    354\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\internals\\blocks.py:705\u001b[0m, in \u001b[0;36mBlock.replace_list\u001b[1;34m(self, src_list, dest_list, inplace, regex)\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[39mif\u001b[39;00m is_string_dtype(values\u001b[39m.\u001b[39mdtype):\n\u001b[0;32m    702\u001b[0m     \u001b[39m# Calculate the mask once, prior to the call of comp\u001b[39;00m\n\u001b[0;32m    703\u001b[0m     \u001b[39m# in order to avoid repeating the same computations\u001b[39;00m\n\u001b[0;32m    704\u001b[0m     mask \u001b[39m=\u001b[39m \u001b[39m~\u001b[39misna(values)\n\u001b[1;32m--> 705\u001b[0m     masks \u001b[39m=\u001b[39m [\n\u001b[0;32m    706\u001b[0m         compare_or_regex_search(values, s[\u001b[39m0\u001b[39m], regex\u001b[39m=\u001b[39mregex, mask\u001b[39m=\u001b[39mmask)\n\u001b[0;32m    707\u001b[0m         \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m pairs\n\u001b[0;32m    708\u001b[0m     ]\n\u001b[0;32m    709\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    710\u001b[0m     \u001b[39m# GH#38086 faster if we know we dont need to check for regex\u001b[39;00m\n\u001b[0;32m    711\u001b[0m     masks \u001b[39m=\u001b[39m [missing\u001b[39m.\u001b[39mmask_missing(values, s[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m pairs]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\internals\\blocks.py:706\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[39mif\u001b[39;00m is_string_dtype(values\u001b[39m.\u001b[39mdtype):\n\u001b[0;32m    702\u001b[0m     \u001b[39m# Calculate the mask once, prior to the call of comp\u001b[39;00m\n\u001b[0;32m    703\u001b[0m     \u001b[39m# in order to avoid repeating the same computations\u001b[39;00m\n\u001b[0;32m    704\u001b[0m     mask \u001b[39m=\u001b[39m \u001b[39m~\u001b[39misna(values)\n\u001b[0;32m    705\u001b[0m     masks \u001b[39m=\u001b[39m [\n\u001b[1;32m--> 706\u001b[0m         compare_or_regex_search(values, s[\u001b[39m0\u001b[39;49m], regex\u001b[39m=\u001b[39;49mregex, mask\u001b[39m=\u001b[39;49mmask)\n\u001b[0;32m    707\u001b[0m         \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m pairs\n\u001b[0;32m    708\u001b[0m     ]\n\u001b[0;32m    709\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    710\u001b[0m     \u001b[39m# GH#38086 faster if we know we dont need to check for regex\u001b[39;00m\n\u001b[0;32m    711\u001b[0m     masks \u001b[39m=\u001b[39m [missing\u001b[39m.\u001b[39mmask_missing(values, s[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m pairs]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\array_algos\\replace.py:112\u001b[0m, in \u001b[0;36mcompare_or_regex_search\u001b[1;34m(a, b, regex, mask)\u001b[0m\n\u001b[0;32m    107\u001b[0m result \u001b[39m=\u001b[39m op(a)\n\u001b[0;32m    109\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, np\u001b[39m.\u001b[39mndarray) \u001b[39mand\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m     \u001b[39m# The shape of the mask can differ to that of the result\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     \u001b[39m# since we may compare only a subset of a's or b's elements\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m     tmp \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mzeros(mask\u001b[39m.\u001b[39;49mshape, dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mbool_)\n\u001b[0;32m    113\u001b[0m     np\u001b[39m.\u001b[39mplace(tmp, mask, result)\n\u001b[0;32m    114\u001b[0m     result \u001b[39m=\u001b[39m tmp\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# User ID's of each impression log:\n",
    "users = User['user_id'].unique()\n",
    "\n",
    "test2 = [i for i in range(len(users))]\n",
    "\n",
    "\n",
    "# Add encodings to dict\n",
    "userid_dict = {}\n",
    "for user in users:\n",
    "    for value in test2:\n",
    "        userid_dict[user] = value\n",
    "        test2.remove(value)\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "# Replace column with encodings:\n",
    "U = th.tensor(User['user_id'].replace(userid_dict))\n",
    "U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n55189', 'n42782', 'n34694', 'n45794', 'n18445', 'n63302', 'n10414', 'n19347', 'n31801', 'Hpad>>', 'Hpad>>']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[243], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m X \u001b[39m=\u001b[39m [item\u001b[39m.\u001b[39mupper() \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m User[\u001b[39m\"\u001b[39m\u001b[39mhistory\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m     24\u001b[0m \u001b[39mprint\u001b[39m(tokenizer(User[\u001b[39m\"\u001b[39m\u001b[39mhistory\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]) \u001b[39m+\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mHpad>>\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m pad_hists \u001b[39m=\u001b[39m [th\u001b[39m.\u001b[39mtensor(tokenizer(User[\u001b[39m\"\u001b[39m\u001b[39mhistory\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]) \u001b[39m+\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m<HPad>\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m*\u001b[39mpad_seq_lengths[i]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N)]\n\u001b[0;32m     29\u001b[0m pad_hists\n",
      "Cell \u001b[1;32mIn[243], line 26\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     23\u001b[0m X \u001b[39m=\u001b[39m [item\u001b[39m.\u001b[39mupper() \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m User[\u001b[39m\"\u001b[39m\u001b[39mhistory\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m     24\u001b[0m \u001b[39mprint\u001b[39m(tokenizer(User[\u001b[39m\"\u001b[39m\u001b[39mhistory\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]) \u001b[39m+\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mHpad>>\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m pad_hists \u001b[39m=\u001b[39m [th\u001b[39m.\u001b[39;49mtensor(tokenizer(User[\u001b[39m\"\u001b[39;49m\u001b[39mhistory\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m0\u001b[39;49m]) \u001b[39m+\u001b[39;49m [\u001b[39m\"\u001b[39;49m\u001b[39m<HPad>\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m*\u001b[39;49mpad_seq_lengths[i]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N)]\n\u001b[0;32m     29\u001b[0m pad_hists\n",
      "\u001b[1;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "# For each impression log: all topics, subtopics and titles embedded and encoded in tensors\n",
    "# First pad topic/subtopic sequences\n",
    "N = len(User['history'])\n",
    "\n",
    "\n",
    "# th.zeros()\n",
    "seq_lengths = th.zeros(N)\n",
    "for i in range(N):\n",
    "    if isinstance(User['history'][i], str):\n",
    "        seq_lengths[i] = len(tokenizer(User['history'][i]))\n",
    "seq_lengths\n",
    "\n",
    "# [item.upper() for item in test]\n",
    "\n",
    "# seq_lengths = [(len(tokenizer(User['history'][i]))) for i in range(len(User['history']))]\n",
    "\n",
    "# Find max sequence length\n",
    "max_seq_length = max(seq_lengths)\n",
    "\n",
    "\n",
    "pad_seq_lengths = ((max_seq_length-seq_lengths).to(th.int32)).tolist()\n",
    "\n",
    "X = [item.upper() for item in User[\"history\"][0]]\n",
    "# print(tokenizer(User[\"history\"][0]) + [\"Hpad>>\"]*2)\n",
    "\n",
    "\n",
    "\n",
    "# NOT WORKING YET: NEED to encode history first\n",
    "pad_hists = th.zeors(N,max_seq_length)\n",
    "for i in range(N):\n",
    "pad_hists = [th.tensor(tokenizer(User[\"history\"][0]) + [\"<HPad>\"]*pad_seq_lengths[i]) ]\n",
    "\n",
    "pad_hists\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewsEncoderModule(topic, subtopic, W).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n55189',\n",
       " 'n42782',\n",
       " 'n34694',\n",
       " 'n45794',\n",
       " 'n18445',\n",
       " 'n63302',\n",
       " 'n10414',\n",
       " 'n19347',\n",
       " 'n31801']"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(User[\"history\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([549, 476, 542,  ..., 535, 500, 556], dtype=torch.int32)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(max_seq_length-seq_lengths).to(th.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "546924c72266054aa1fd3b326110d7f9571ebb101ba9d1b066b50dfc47c2fe3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
