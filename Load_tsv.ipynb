{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data contains 17 topics and 264 subtopics\n"
     ]
    }
   ],
   "source": [
    "# Description: Load tsv file\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load tsv file\n",
    "News = pd.read_csv('MINDsmall_train/news.tsv', sep='\\t', header=None)\n",
    "News.columns = ['news_id', 'category', 'subcategory', 'title', 'abstract', 'url', 'title_entities', 'abstract_entities']\n",
    "\n",
    "#News = News.drop(16459)\n",
    "#News = News.drop(2044)\n",
    "\n",
    "\n",
    "User = pd.read_csv('MINDsmall_train/behaviors.tsv', sep='\\t', header=None)\n",
    "User.columns = ['impression_id', 'user_id', 'time', 'history', 'impressions']\n",
    "\n",
    "User = User.dropna()\n",
    "\n",
    "topic_size = News['category'].nunique()\n",
    "subtopic_size = News['subcategory'].nunique()\n",
    "\n",
    "print(f\"Data contains {topic_size} topics and {subtopic_size} subtopics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Vocabulary for users and topics\n",
    "from torchtext import vocab\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import torch as th\n",
    "from LSTUR import GloVe\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "User_vocab = vocab.build_vocab_from_iterator([[id] for id in User['user_id']])\n",
    "News_vocab = vocab.build_vocab_from_iterator([[id] for id in  News['news_id']])\n",
    "Category_vocab = vocab.build_vocab_from_iterator([[Category] for Category in News['category']])\n",
    "Subcategory_vocab = vocab.build_vocab_from_iterator([[Category] for Category in News['subcategory']])\n",
    "\n",
    "# Define Vocabulary for title and abstract\n",
    "max_title_length = max([len(tokenizer(title)) for title in News['title']])\n",
    "max_history_length = max([len(history.split(\" \")) for history in User['history']])\n",
    "max_impressions_length = max([len(impressions.split(\" \")) for impressions in User['impressions']])\n",
    "\n",
    "# Define Datapoint to tensor\n",
    "def Datapoint_to_Encodings(User):\n",
    "\n",
    "    History = News_vocab.lookup_indices(User.history.split(\" \"))\n",
    "    User_en = User_vocab.__getitem__(User.user_id)\n",
    "    Impressions = User.impressions.split(\" \")\n",
    "    Impressions,Clicked = map(list, zip(*[Impression.split(\"-\") for Impression in Impressions]))\n",
    "    \n",
    "    Impressions = News_vocab.lookup_indices(Impressions)\n",
    "    Clicked = [int(Click) for Click in Clicked]\n",
    "\n",
    "\n",
    "    History, User_en, Impressions, Clicked = map(th.tensor, [History, User_en, Impressions, Clicked])\n",
    "\n",
    "    return History, User_en, Impressions, Clicked\n",
    "\n",
    "# Pack Title\n",
    "def pack_Title(title,max_length):\n",
    "\n",
    "    src_len, _ = title.size()\n",
    "\n",
    "    title_reformated = th.zeros(max_length,300)\n",
    "\n",
    "    title_reformated[:src_len,:] = title\n",
    "\n",
    "    return title_reformated, src_len\n",
    "\n",
    "\n",
    "# Get Numeric Artikles representation\n",
    "def get_Article_Encodings(Artikle):\n",
    "\n",
    "\n",
    "    title = GloVe.get_vecs_by_tokens(tokenizer(Artikle['title']))\n",
    "    \n",
    "    #Abstract = [tokenizer(abstract) for abstract in Artikle['abstract']]\n",
    "    Category = Category_vocab.__getitem__(Artikle['category'])\n",
    "    Subcategory = Subcategory_vocab.__getitem__(Artikle['subcategory'])\n",
    "\n",
    "    title, title_len = pack_Title(title,max_title_length)\n",
    "\n",
    "    Category, Subcategory, title_len = map(th.tensor, [Category, Subcategory, title_len])\n",
    "\n",
    "    \n",
    "\n",
    "    return Category, Subcategory, title, title_len\n",
    "\n",
    "# Store all News in Dictionary for faster access\n",
    "News_tensors = {}\n",
    "\n",
    "for i in range(len(News)):\n",
    "    News_tensors[News_vocab.__getitem__(News['news_id'][i])] = get_Article_Encodings(News.loc[i])\n",
    "\n",
    "# Get Numeric User representation\n",
    "def Datapoint_to_tensor(User):\n",
    "\n",
    "    History, User_en, Impressions, Clicked = Datapoint_to_Encodings(User)\n",
    "\n",
    "    History_tensor = th.zeros(max_history_length,max_title_length,300)\n",
    "    Category = th.zeros(max_history_length)\n",
    "    Subcategory = th.zeros(max_history_length)\n",
    "    datapoint_len = len(History)\n",
    "\n",
    "    for idx,article in enumerate(History):\n",
    "        Category[idx], Subcategory[idx], History_tensor[idx], _ = News_tensors[article.item()]\n",
    "\n",
    "    Impressions_tensor = th.zeros(max_impressions_length,max_title_length,300)\n",
    "    Category_Impressions = th.zeros(max_impressions_length)\n",
    "    Subcategory_Impressions = th.zeros(max_impressions_length)\n",
    "    Impressions_len = len(Impressions)\n",
    "\n",
    "    datapoint_len, Impressions_len = map(th.tensor, [datapoint_len, Impressions_len])\n",
    "\n",
    "\n",
    "    for idx,article in enumerate(Impressions):\n",
    "        Category_Impressions[idx], Subcategory_Impressions[idx], Impressions_tensor[idx], _ = News_tensors[article.item()]\n",
    "    \n",
    "    Clicked = Clicked.argmax()+1\n",
    "\n",
    "    return User_en, Category, Subcategory, History_tensor, datapoint_len, Category_Impressions, Subcategory_Impressions, Impressions_tensor, Impressions_len, Clicked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "User_en, Category, Subcategory, History_tensor, datapoint_len, Category_Impressions, Subcategory_Impressions, Impressions_tensor, Impressions_len, Clicked = Datapoint_to_tensor(User.loc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(User['history'][1214].split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "his = [history.split(\" \") for history in User['history']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "558"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note to self. Fix Max length (Cleaning af data evt.)\n",
    "\n",
    "\n",
    "max_history_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Impressions_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([558])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Subcategory.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "History, User_en, Impressions, Clicked = Datapoint_to_Encodings(User.loc[0])\n",
    "\n",
    "History_tensor = th.zeros(max_history_length,max_title_length,300)\n",
    "Category = th.zeros(max_history_length)\n",
    "Subcategory = th.zeros(max_history_length)\n",
    "datapoint_len = len(History)\n",
    "\n",
    "for idx,article in enumerate(History):\n",
    "    Category[idx], Subcategory[idx], History_tensor[idx], _ = News_tensors[article.item()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(39409)\n",
      "tensor(28620)\n",
      "tensor(21520)\n",
      "tensor(31231)\n",
      "tensor(7374)\n",
      "tensor(46560)\n",
      "tensor(367)\n",
      "tensor(8167)\n",
      "tensor(19019)\n"
     ]
    }
   ],
   "source": [
    "for article in History:\n",
    "    print(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([39409, 28620, 21520, 31231,  7374, 46560,   367,  8167, 19019]),\n",
       " tensor(14242),\n",
       " tensor([39853, 22430]),\n",
       " tensor([1, 0]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Datapoint_to_Encodings(User.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([39409, 28620, 21520, 31231,  7374, 46560,   367,  8167, 19019]),\n",
       " tensor(14610),\n",
       " tensor([39853, 22430]),\n",
       " tensor([1, 0]))"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Datapoint_to_Encodings(User.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[39409, 28620, 21520, 31231, 7374, 46560, 367, 8167, 19019]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "News_vocab.lookup_indices(User.history[0].split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_title_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1683: And the bride wore sparkles! First look at Jennifer Lawrence and Cooke Maroney as a married couple as they leave their haunted Rhode Island castle wedding venue after partying with A-list guests including Sienna Miller and Kris Jenner until 5.30am\n",
      "\n",
      "2044: 'If I had never dialed the police, she'd still be alive': Neighbor who called a non-emergency number to ask for a 2am welfare check on a woman, 28, because her front door was open says he is horrified she was killed in her own home by a cop\n",
      "\n",
      "3402: Billy Connolly says his Parkinson's is the 'first thing I think about when I wake up' as he reveals how he is still adapting to life with the condition but says he could make a return to live stand-up\n",
      "\n",
      "13645: Dad-of-two, 37, drank 200 bottles of wine in two weeks at peak of booze and drugs battle that left him on the streets - but he's now turned his life around and is a Thai boxing champ\n",
      "\n",
      "16459: The Price You Pay: The spiraling cost of college\tIn our new series, The Price You Pay,\" we look at the rising cost of attending a public college, which has risen ten-fold since 1965. Tony Dokoupil reports on how amenities at some universities, aimed at attracting more students, are adding to the spiralling cost of higher education.\n",
      "\n",
      "19476: Brewer makes his 24th career start in his 29th game Thursday night when the Bears (7-0, 4-0 Big 12) put a nine-game winning streak on the line at home against West Virginia (3-4, 1-3).\n",
      "\n",
      "23218: Russian spy Maria Butina, 30, will be released from jail on Friday and escorted by two ICE agents back to Moscow after serving 16 months of her 18-month sentence as her life behind bars of five-mile runs and working at the prison cafeteria is revealed\n",
      "\n",
      "28526: An NYC penthouse once owned by Demi Moore just hit the market for $50 million, and she's just one of the celebs who have called the iconic Central Park building home. Here's a look inside.\n",
      "\n",
      "29790: EXCLUSIVE: Given up for adoption at two, a grueling Soviet childhood and a violent marriage: The true story of the homeless 'voice of an angel' is revealed as friends and family rejoice over finding the prodigy they feared they had lost forever\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for idx,title in enumerate(News['title']):\n",
    "\n",
    "    if len(tokenizer(title)) > 40:\n",
    "        print(f\"{idx}: {title}\")\n",
    "        print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The five-bedroom penthouse spans three floors in one of the towers of the San Remo building, a 28-story luxury Manhattan condo built in 1930.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "News.loc[28526]['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikolaj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from LSTUR import NewsEncoder, TitleEncoder, TopicEncoder, GloVe\n",
    "import torch as th\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "topic_embedding_dim = 100\n",
    "subtopic_embedding_dim = 100\n",
    "word_size = 100\n",
    "\n",
    "\n",
    "NewsEncoderModule = NewsEncoder(100, 100, topic_size, subtopic_size, 10000)\n",
    "TitleEncoderModule = TitleEncoder(100)\n",
    "TopicEncoderModule = TopicEncoder(100, 100, topic_size, subtopic_size)\n",
    "\n",
    "topic = th.tensor([0],dtype=th.int32)\n",
    "subtopic = th.tensor([0],dtype=th.int32)\n",
    "\n",
    "title = tokenizer(News['title'][0])\n",
    "W = GloVe.get_vecs_by_tokens(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([51282])\n",
      "torch.Size([51282])\n"
     ]
    }
   ],
   "source": [
    "# Encode categories and subcategories:\n",
    "categories = News['category'].unique()\n",
    "subcategories = News['subcategory'].unique()\n",
    "\n",
    "test = [i for i in range(len(categories))]\n",
    "test2 = [i for i in range(len(subcategories))]\n",
    "\n",
    "# Add encodings to dict\n",
    "res = {}\n",
    "for cat in categories:\n",
    "    for value in test:\n",
    "        res[cat] = value\n",
    "        test.remove(value)\n",
    "        break\n",
    "\n",
    "\n",
    "res2 = {}\n",
    "for subcat in subcategories:\n",
    "    for value in test2:\n",
    "        res2[subcat] = value\n",
    "        test2.remove(value)\n",
    "        break\n",
    "\n",
    "\n",
    "# Replace column with encodings:\n",
    "C = th.tensor(News['category'].replace(res))\n",
    "SC = th.tensor(News['subcategory'].replace(res2))\n",
    "\n",
    "print(C.shape)\n",
    "print(SC.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'brands',\n",
       " 'queen',\n",
       " 'elizabeth',\n",
       " ',',\n",
       " 'prince',\n",
       " 'charles',\n",
       " ',',\n",
       " 'and',\n",
       " 'prince',\n",
       " 'philip',\n",
       " 'swear',\n",
       " 'by']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get titles lengths\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "lengths = th.tensor([len(tokenizer(News['title'][i])) for i in range(News['title'].size)])\n",
    "\n",
    "\n",
    "# Pad titles\n",
    "maxlength = max(lengths)\n",
    "padlengths = (maxlength-lengths).tolist()\n",
    "padtitles = [tokenizer(News[\"title\"][i] + \" <Pad>\"*padlengths[i]) for i in range(len(padlengths))]\n",
    "\n",
    "\n",
    "\n",
    "# Embed titles\n",
    "Article_embedding = th.zeros(len(padtitles),maxlength,300)\n",
    "i = 0\n",
    "for t in padtitles:\n",
    "    Article_embedding[i] = GloVe.get_vecs_by_tokens(t)\n",
    "    i+=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51282\n",
      "torch.Size([64, 300])\n"
     ]
    }
   ],
   "source": [
    "# Dictionary of articles from their ID's\n",
    "newsid = News['news_id']\n",
    "article_dict = {newsid[i]:Article_embedding[i] for i in range(len(padtitles))}\n",
    "\n",
    "print(len(article_dict))\n",
    "print(article_dict[\"N55189\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[127], line 18\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m# Replace column with encodings:\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m U \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mtensor(User[\u001b[39m'\u001b[39;49m\u001b[39muser_id\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mreplace(userid_dict))\n\u001b[0;32m     19\u001b[0m U\u001b[39m.\u001b[39mshape\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\series.py:5380\u001b[0m, in \u001b[0;36mSeries.replace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   5362\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(\n\u001b[0;32m   5363\u001b[0m     version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mto_replace\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   5364\u001b[0m )\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5378\u001b[0m     method: Literal[\u001b[39m\"\u001b[39m\u001b[39mpad\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mffill\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbfill\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m|\u001b[39m lib\u001b[39m.\u001b[39mNoDefault \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mno_default,\n\u001b[0;32m   5379\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 5380\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mreplace(\n\u001b[0;32m   5381\u001b[0m         to_replace\u001b[39m=\u001b[39;49mto_replace,\n\u001b[0;32m   5382\u001b[0m         value\u001b[39m=\u001b[39;49mvalue,\n\u001b[0;32m   5383\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5384\u001b[0m         limit\u001b[39m=\u001b[39;49mlimit,\n\u001b[0;32m   5385\u001b[0m         regex\u001b[39m=\u001b[39;49mregex,\n\u001b[0;32m   5386\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[0;32m   5387\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\generic.py:7188\u001b[0m, in \u001b[0;36mNDFrame.replace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   7185\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   7186\u001b[0m         to_replace, value \u001b[39m=\u001b[39m keys, values\n\u001b[1;32m-> 7188\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreplace(\n\u001b[0;32m   7189\u001b[0m         to_replace, value, inplace\u001b[39m=\u001b[39;49minplace, limit\u001b[39m=\u001b[39;49mlimit, regex\u001b[39m=\u001b[39;49mregex\n\u001b[0;32m   7190\u001b[0m     )\n\u001b[0;32m   7191\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   7192\u001b[0m \n\u001b[0;32m   7193\u001b[0m     \u001b[39m# need a non-zero len on all axes\u001b[39;00m\n\u001b[0;32m   7194\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\series.py:5380\u001b[0m, in \u001b[0;36mSeries.replace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   5362\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(\n\u001b[0;32m   5363\u001b[0m     version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mto_replace\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   5364\u001b[0m )\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5378\u001b[0m     method: Literal[\u001b[39m\"\u001b[39m\u001b[39mpad\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mffill\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbfill\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m|\u001b[39m lib\u001b[39m.\u001b[39mNoDefault \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mno_default,\n\u001b[0;32m   5379\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 5380\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mreplace(\n\u001b[0;32m   5381\u001b[0m         to_replace\u001b[39m=\u001b[39;49mto_replace,\n\u001b[0;32m   5382\u001b[0m         value\u001b[39m=\u001b[39;49mvalue,\n\u001b[0;32m   5383\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5384\u001b[0m         limit\u001b[39m=\u001b[39;49mlimit,\n\u001b[0;32m   5385\u001b[0m         regex\u001b[39m=\u001b[39;49mregex,\n\u001b[0;32m   5386\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[0;32m   5387\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\generic.py:7237\u001b[0m, in \u001b[0;36mNDFrame.replace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   7232\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(to_replace) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(value):\n\u001b[0;32m   7233\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   7234\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReplacement lists must match in length. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   7235\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(to_replace)\u001b[39m}\u001b[39;00m\u001b[39m got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(value)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   7236\u001b[0m         )\n\u001b[1;32m-> 7237\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mreplace_list(\n\u001b[0;32m   7238\u001b[0m         src_list\u001b[39m=\u001b[39;49mto_replace,\n\u001b[0;32m   7239\u001b[0m         dest_list\u001b[39m=\u001b[39;49mvalue,\n\u001b[0;32m   7240\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   7241\u001b[0m         regex\u001b[39m=\u001b[39;49mregex,\n\u001b[0;32m   7242\u001b[0m     )\n\u001b[0;32m   7244\u001b[0m \u001b[39melif\u001b[39;00m to_replace \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   7245\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\n\u001b[0;32m   7246\u001b[0m         is_re_compilable(regex)\n\u001b[0;32m   7247\u001b[0m         \u001b[39mor\u001b[39;00m is_list_like(regex)\n\u001b[0;32m   7248\u001b[0m         \u001b[39mor\u001b[39;00m is_dict_like(regex)\n\u001b[0;32m   7249\u001b[0m     ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\internals\\managers.py:487\u001b[0m, in \u001b[0;36mBaseBlockManager.replace_list\u001b[1;34m(self, src_list, dest_list, inplace, regex)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"do a list replace\"\"\"\u001b[39;00m\n\u001b[0;32m    485\u001b[0m inplace \u001b[39m=\u001b[39m validate_bool_kwarg(inplace, \u001b[39m\"\u001b[39m\u001b[39minplace\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 487\u001b[0m bm \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\n\u001b[0;32m    488\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mreplace_list\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    489\u001b[0m     src_list\u001b[39m=\u001b[39;49msrc_list,\n\u001b[0;32m    490\u001b[0m     dest_list\u001b[39m=\u001b[39;49mdest_list,\n\u001b[0;32m    491\u001b[0m     inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m    492\u001b[0m     regex\u001b[39m=\u001b[39;49mregex,\n\u001b[0;32m    493\u001b[0m )\n\u001b[0;32m    494\u001b[0m bm\u001b[39m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m    495\u001b[0m \u001b[39mreturn\u001b[39;00m bm\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(b, f)(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n\u001b[0;32m    354\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\internals\\blocks.py:705\u001b[0m, in \u001b[0;36mBlock.replace_list\u001b[1;34m(self, src_list, dest_list, inplace, regex)\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[39mif\u001b[39;00m is_string_dtype(values\u001b[39m.\u001b[39mdtype):\n\u001b[0;32m    702\u001b[0m     \u001b[39m# Calculate the mask once, prior to the call of comp\u001b[39;00m\n\u001b[0;32m    703\u001b[0m     \u001b[39m# in order to avoid repeating the same computations\u001b[39;00m\n\u001b[0;32m    704\u001b[0m     mask \u001b[39m=\u001b[39m \u001b[39m~\u001b[39misna(values)\n\u001b[1;32m--> 705\u001b[0m     masks \u001b[39m=\u001b[39m [\n\u001b[0;32m    706\u001b[0m         compare_or_regex_search(values, s[\u001b[39m0\u001b[39m], regex\u001b[39m=\u001b[39mregex, mask\u001b[39m=\u001b[39mmask)\n\u001b[0;32m    707\u001b[0m         \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m pairs\n\u001b[0;32m    708\u001b[0m     ]\n\u001b[0;32m    709\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    710\u001b[0m     \u001b[39m# GH#38086 faster if we know we dont need to check for regex\u001b[39;00m\n\u001b[0;32m    711\u001b[0m     masks \u001b[39m=\u001b[39m [missing\u001b[39m.\u001b[39mmask_missing(values, s[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m pairs]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\internals\\blocks.py:706\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[39mif\u001b[39;00m is_string_dtype(values\u001b[39m.\u001b[39mdtype):\n\u001b[0;32m    702\u001b[0m     \u001b[39m# Calculate the mask once, prior to the call of comp\u001b[39;00m\n\u001b[0;32m    703\u001b[0m     \u001b[39m# in order to avoid repeating the same computations\u001b[39;00m\n\u001b[0;32m    704\u001b[0m     mask \u001b[39m=\u001b[39m \u001b[39m~\u001b[39misna(values)\n\u001b[0;32m    705\u001b[0m     masks \u001b[39m=\u001b[39m [\n\u001b[1;32m--> 706\u001b[0m         compare_or_regex_search(values, s[\u001b[39m0\u001b[39;49m], regex\u001b[39m=\u001b[39;49mregex, mask\u001b[39m=\u001b[39;49mmask)\n\u001b[0;32m    707\u001b[0m         \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m pairs\n\u001b[0;32m    708\u001b[0m     ]\n\u001b[0;32m    709\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    710\u001b[0m     \u001b[39m# GH#38086 faster if we know we dont need to check for regex\u001b[39;00m\n\u001b[0;32m    711\u001b[0m     masks \u001b[39m=\u001b[39m [missing\u001b[39m.\u001b[39mmask_missing(values, s[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m pairs]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\array_algos\\replace.py:112\u001b[0m, in \u001b[0;36mcompare_or_regex_search\u001b[1;34m(a, b, regex, mask)\u001b[0m\n\u001b[0;32m    107\u001b[0m result \u001b[39m=\u001b[39m op(a)\n\u001b[0;32m    109\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, np\u001b[39m.\u001b[39mndarray) \u001b[39mand\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m     \u001b[39m# The shape of the mask can differ to that of the result\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     \u001b[39m# since we may compare only a subset of a's or b's elements\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m     tmp \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mzeros(mask\u001b[39m.\u001b[39;49mshape, dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mbool_)\n\u001b[0;32m    113\u001b[0m     np\u001b[39m.\u001b[39mplace(tmp, mask, result)\n\u001b[0;32m    114\u001b[0m     result \u001b[39m=\u001b[39m tmp\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# User ID's of each impression log:\n",
    "users = User['user_id'].unique()\n",
    "\n",
    "test2 = [i for i in range(len(users))]\n",
    "\n",
    "\n",
    "# Add encodings to dict\n",
    "userid_dict = {}\n",
    "for user in users:\n",
    "    for value in test2:\n",
    "        userid_dict[user] = value\n",
    "        test2.remove(value)\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "# Replace column with encodings:\n",
    "U = th.tensor(User['user_id'].replace(userid_dict))\n",
    "U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n55189', 'n42782', 'n34694', 'n45794', 'n18445', 'n63302', 'n10414', 'n19347', 'n31801', 'Hpad>>', 'Hpad>>']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[243], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m X \u001b[39m=\u001b[39m [item\u001b[39m.\u001b[39mupper() \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m User[\u001b[39m\"\u001b[39m\u001b[39mhistory\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m     24\u001b[0m \u001b[39mprint\u001b[39m(tokenizer(User[\u001b[39m\"\u001b[39m\u001b[39mhistory\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]) \u001b[39m+\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mHpad>>\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m pad_hists \u001b[39m=\u001b[39m [th\u001b[39m.\u001b[39mtensor(tokenizer(User[\u001b[39m\"\u001b[39m\u001b[39mhistory\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]) \u001b[39m+\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m<HPad>\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m*\u001b[39mpad_seq_lengths[i]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N)]\n\u001b[0;32m     29\u001b[0m pad_hists\n",
      "Cell \u001b[1;32mIn[243], line 26\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     23\u001b[0m X \u001b[39m=\u001b[39m [item\u001b[39m.\u001b[39mupper() \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m User[\u001b[39m\"\u001b[39m\u001b[39mhistory\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m     24\u001b[0m \u001b[39mprint\u001b[39m(tokenizer(User[\u001b[39m\"\u001b[39m\u001b[39mhistory\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]) \u001b[39m+\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mHpad>>\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m pad_hists \u001b[39m=\u001b[39m [th\u001b[39m.\u001b[39;49mtensor(tokenizer(User[\u001b[39m\"\u001b[39;49m\u001b[39mhistory\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m0\u001b[39;49m]) \u001b[39m+\u001b[39;49m [\u001b[39m\"\u001b[39;49m\u001b[39m<HPad>\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m*\u001b[39;49mpad_seq_lengths[i]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N)]\n\u001b[0;32m     29\u001b[0m pad_hists\n",
      "\u001b[1;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "# For each impression log: all topics, subtopics and titles embedded and encoded in tensors\n",
    "# First pad topic/subtopic sequences\n",
    "N = len(User['history'])\n",
    "\n",
    "\n",
    "# th.zeros()\n",
    "seq_lengths = th.zeros(N)\n",
    "for i in range(N):\n",
    "    if isinstance(User['history'][i], str):\n",
    "        seq_lengths[i] = len(tokenizer(User['history'][i]))\n",
    "seq_lengths\n",
    "\n",
    "# [item.upper() for item in test]\n",
    "\n",
    "# seq_lengths = [(len(tokenizer(User['history'][i]))) for i in range(len(User['history']))]\n",
    "\n",
    "# Find max sequence length\n",
    "max_seq_length = max(seq_lengths)\n",
    "\n",
    "\n",
    "pad_seq_lengths = ((max_seq_length-seq_lengths).to(th.int32)).tolist()\n",
    "\n",
    "X = [item.upper() for item in User[\"history\"][0]]\n",
    "# print(tokenizer(User[\"history\"][0]) + [\"Hpad>>\"]*2)\n",
    "\n",
    "\n",
    "\n",
    "# NOT WORKING YET: NEED to encode history first\n",
    "pad_hists = th.zeors(N,max_seq_length)\n",
    "for i in range(N):\n",
    "pad_hists = [th.tensor(tokenizer(User[\"history\"][0]) + [\"<HPad>\"]*pad_seq_lengths[i]) ]\n",
    "\n",
    "pad_hists\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewsEncoderModule(topic, subtopic, W).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n55189',\n",
       " 'n42782',\n",
       " 'n34694',\n",
       " 'n45794',\n",
       " 'n18445',\n",
       " 'n63302',\n",
       " 'n10414',\n",
       " 'n19347',\n",
       " 'n31801']"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(User[\"history\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([549, 476, 542,  ..., 535, 500, 556], dtype=torch.int32)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(max_seq_length-seq_lengths).to(th.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "546924c72266054aa1fd3b326110d7f9571ebb101ba9d1b066b50dfc47c2fe3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
