{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/magnusharder/Documents/UNI-DTU/6. Semester/Bachelor Projekt/News-Recommendations/DataIterator.py:139: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.user_data['history_length'][self.user_data['history_length'] > 50] = 50\n",
      "/Users/magnusharder/Documents/UNI-DTU/6. Semester/Bachelor Projekt/News-Recommendations/DataIterator.py:139: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.user_data['history_length'][self.user_data['history_length'] > 50] = 50\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "\n",
    "from General.Utils import ValidateModel\n",
    "from DataIterator import NewsDataset as NewsDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from TestData.MindDependencies.Metrics import cal_metric\n",
    "\n",
    "\n",
    "import torch as th\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "# Import Hparam\n",
    "with open('Data/MINDdemo_utils/lstur.yaml','r') as stream:\n",
    "    hparams = yaml.safe_load(stream)\n",
    "\n",
    "# Import word_vec\n",
    "word_embedding = np.load('Data/MINDdemo_utils/embedding_all.npy')\n",
    "\n",
    "# Import word_vec\n",
    "word_embedding = np.load('Data/MINDdemo_utils/embedding_all.npy')\n",
    "word_embedding = word_embedding.astype(np.float32)\n",
    "\n",
    "\n",
    "# %%\n",
    "# Define Device\n",
    "device = 'cuda' if th.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Define Data, Dataset and DataLoaders\n",
    "train_behaviors_file = 'Data/MINDdemo_train/behaviors.tsv'\n",
    "train_news_file = 'Data/MINDdemo_train/news.tsv'\n",
    "word_dict_file = 'Data/MINDdemo_utils/word_dict_all.pkl'\n",
    "user_dict_file = 'Data/MINDdemo_utils/uid2index.pkl'\n",
    "\n",
    "valid_behaviors_file = 'Data/MINDdemo_dev/behaviors.tsv'\n",
    "valid_news_file = 'Data/MINDdemo_dev/news.tsv'\n",
    "\n",
    "# %%\n",
    "import pickle\n",
    "\n",
    "with open (\"Data/MINDdemo_utils/word_dict.pkl\", \"rb\") as f:\n",
    "    word_dict = pickle.load(f)\n",
    "with open (\"Data/MINDdemo_utils/uid2index.pkl\", \"rb\") as f:\n",
    "    uid2index = pickle.load(f)\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class HyperParams:\n",
    "    batch_size: int\n",
    "    title_size: int\n",
    "    his_size: int\n",
    "    wordDict_file: str\n",
    "    userDict_file: str\n",
    "\n",
    "hparamsdata = HyperParams(\n",
    "    batch_size=32,\n",
    "    title_size=20,\n",
    "    his_size=50,\n",
    "    wordDict_file=word_dict_file,\n",
    "    userDict_file=user_dict_file,\n",
    ")\n",
    "\n",
    "TrainData = NewsDataset(train_behaviors_file, train_news_file, word_dict_file, userid_dict=uid2index,max_history_length=50,transformer=True,train=True)\n",
    "TestData = NewsDataset(valid_behaviors_file, valid_news_file, word_dict_file, userid_dict=uid2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TestData.LSTURMind import NewsEncoder\n",
    "newsencoder = NewsEncoder(attention_dim = hparams['model']['attention_hidden_dim'],\n",
    "                        word_emb_dim = hparams['model']['word_emb_dim'],\n",
    "                        dropout = hparams['model']['dropout'],\n",
    "                        filter_num = hparams['model']['filter_num'],\n",
    "                        windows_size = hparams['model']['window_size'],\n",
    "                        gru_unit = hparams['model']['gru_unit'],\n",
    "                        word_vectors = word_embedding,\n",
    "                        device = device\n",
    "                        )   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "# Import Model\n",
    "from Models.Transformer import lstransformer\n",
    "impressions_length = 50\n",
    "\n",
    "\n",
    "TransformerModule = lstransformer(his_size = hparamsdata.his_size,\n",
    "                                  d_model = hparams['model']['gru_unit'], \n",
    "                                  ffdim = 800, \n",
    "                                  nhead = 1, \n",
    "                                  num_layers = 3, \n",
    "                                  newsencoder = newsencoder,\n",
    "                                  user_vocab_size=uid2index.__len__() + 1,\n",
    "                                  device=device,\n",
    "                                  dropout=0.2,\n",
    "                                )\n",
    "\n",
    "# Move to device\n",
    "model = TransformerModule.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_key(batch_size,data_length, actual_length):\n",
    "\n",
    "    mask = th.zeros((batch_size,data_length))\n",
    "\n",
    "\n",
    "    for _ in range(batch_size):\n",
    "        mask[_,actual_length[_]:] = 1\n",
    "\n",
    "    return mask.bool()\n",
    "\n",
    "def get_mask(batch_size, data_length, actual_length):\n",
    "\n",
    "    mask = th.zeros((batch_size,data_length,data_length))\n",
    "\n",
    "\n",
    "    for _ in range(batch_size):\n",
    "        mask[_,:,actual_length[_]:] = float('-inf')\n",
    "        \n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 3/100 [00:19<10:35,  6.55s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m     loss_val \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     32\u001b[0m     \u001b[39m# Backpropagation\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     35\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     37\u001b[0m loss_epoch\u001b[39m.\u001b[39mappend(loss_val\u001b[39m/\u001b[39miters)\n",
      "File \u001b[0;32m~/Documents/UNI-DTU/6. Semester/Bachelor Projekt/News-Recommendations/.venv/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/UNI-DTU/6. Semester/Bachelor Projekt/News-Recommendations/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Train = DataLoader(TrainData, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "loss_fn = th.nn.CrossEntropyLoss()\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "iters = 20\n",
    "\n",
    "loss_epoch = []\n",
    "for epoch in range(1):\n",
    "    print(f'Epoch {epoch}')\n",
    "\n",
    "    loss_val = 0\n",
    "    for i in tqdm(range(iters)):\n",
    "\n",
    "        # Zero Gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Get Data\n",
    "        user_id, history_title, history_abstract, history_length, impressions_title, impressions_abstract, impressions_length, labels, n_positive = next(iter(Train))\n",
    "\n",
    "        # Compute Mask\n",
    "        mask_key = get_mask_key(user_id.shape[0],50, history_length)\n",
    "\n",
    "        # Compute scores\n",
    "        scores = model(user_id, history_title, mask_key, impressions_title)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(scores, labels.argmax(dim=1).reshape(-1,1))\n",
    "        loss_val += loss.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    loss_epoch.append(loss_val/iters)\n",
    "\n",
    "\n",
    "# plot loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_epoch)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 3 2 4]\n"
     ]
    }
   ],
   "source": [
    "user_id, history_title, history_abstract, history_length, impressions_title, impressions_abstract, impressions_length, labels, n_positive = next(iter(Train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_mask = get_mask(32,50, history_length)\n",
    "tgt_mask = get_mask(32,impressions_title.shape[1], impressions_length)\n",
    "his_mask = get_mask_key(32,50,history_length)\n",
    "impressions_mask = get_mask_key(32,impressions_title.shape[1],impressions_length)\n",
    "\n",
    "score_mask = model(user_id, history_title, src_mask, his_mask, impressions_title, tgt_mask, impressions_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 87,   7,   3,  70,   2,  34, 128,  11,  93,  56,  49,   9,  16,  26,\n",
       "         23,  37,  31,  23,  69,  19,  26, 120,   2,  34,  38,  35,  87,   4,\n",
       "         13,  21,  21, 124])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impressions_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0038],\n",
       "        [0.0038],\n",
       "        [0.0044],\n",
       "        [0.0034],\n",
       "        [0.0026],\n",
       "        [0.0031],\n",
       "        [0.0061],\n",
       "        [0.0047],\n",
       "        [0.0044],\n",
       "        [0.0055],\n",
       "        [0.0032],\n",
       "        [0.0033],\n",
       "        [0.0033],\n",
       "        [0.0048],\n",
       "        [0.0020],\n",
       "        [0.0045],\n",
       "        [0.0017],\n",
       "        [0.0052],\n",
       "        [0.0028],\n",
       "        [0.0032],\n",
       "        [0.0028],\n",
       "        [0.0020],\n",
       "        [0.0044],\n",
       "        [0.0038],\n",
       "        [0.0037],\n",
       "        [0.0037],\n",
       "        [0.0032],\n",
       "        [0.0028],\n",
       "        [0.0033],\n",
       "        [0.0032],\n",
       "        [0.0021],\n",
       "        [0.0035],\n",
       "        [0.0026],\n",
       "        [0.0021],\n",
       "        [0.0033],\n",
       "        [0.0019],\n",
       "        [0.0026],\n",
       "        [0.0027],\n",
       "        [0.0014],\n",
       "        [0.0026],\n",
       "        [0.0047],\n",
       "        [0.0045],\n",
       "        [0.0051],\n",
       "        [0.0025],\n",
       "        [0.0058],\n",
       "        [0.0018],\n",
       "        [0.0034],\n",
       "        [0.0017],\n",
       "        [0.0023],\n",
       "        [0.0033],\n",
       "        [0.0039],\n",
       "        [0.0019],\n",
       "        [0.0022],\n",
       "        [0.0014],\n",
       "        [0.0023],\n",
       "        [0.0029],\n",
       "        [0.0029],\n",
       "        [0.0043],\n",
       "        [0.0024],\n",
       "        [0.0030],\n",
       "        [0.0035],\n",
       "        [0.0030],\n",
       "        [0.0036],\n",
       "        [0.0052],\n",
       "        [0.0033],\n",
       "        [0.0036],\n",
       "        [0.0029],\n",
       "        [0.0030],\n",
       "        [0.0046],\n",
       "        [0.0026],\n",
       "        [0.0023],\n",
       "        [0.0026],\n",
       "        [0.0034],\n",
       "        [0.0050],\n",
       "        [0.0023],\n",
       "        [0.0044],\n",
       "        [0.0034],\n",
       "        [0.0044],\n",
       "        [0.0043],\n",
       "        [0.0038],\n",
       "        [0.0024],\n",
       "        [0.0030],\n",
       "        [0.0026],\n",
       "        [0.0015],\n",
       "        [0.0022],\n",
       "        [0.0033],\n",
       "        [0.0031],\n",
       "        [0.0014],\n",
       "        [0.0014],\n",
       "        [0.0055],\n",
       "        [0.0032],\n",
       "        [0.0013],\n",
       "        [0.0025],\n",
       "        [0.0017],\n",
       "        [0.0033],\n",
       "        [0.0056],\n",
       "        [0.0037],\n",
       "        [0.0017],\n",
       "        [0.0046],\n",
       "        [0.0027],\n",
       "        [0.0048],\n",
       "        [0.0040],\n",
       "        [0.0038],\n",
       "        [0.0036],\n",
       "        [0.0028],\n",
       "        [0.0030],\n",
       "        [0.0029],\n",
       "        [0.0042],\n",
       "        [0.0048],\n",
       "        [0.0023],\n",
       "        [0.0041],\n",
       "        [0.0015],\n",
       "        [0.0026],\n",
       "        [0.0053],\n",
       "        [0.0029],\n",
       "        [0.0053],\n",
       "        [0.0038],\n",
       "        [0.0027],\n",
       "        [0.0017],\n",
       "        [0.0045],\n",
       "        [0.0039],\n",
       "        [0.0042],\n",
       "        [0.0056],\n",
       "        [0.0030],\n",
       "        [0.0016],\n",
       "        [0.0033],\n",
       "        [0.0023],\n",
       "        [0.0035],\n",
       "        [0.0026],\n",
       "        [0.0028],\n",
       "        [0.0038],\n",
       "        [0.0018],\n",
       "        [0.0042],\n",
       "        [0.0024],\n",
       "        [0.0016],\n",
       "        [0.0030],\n",
       "        [0.0029],\n",
       "        [0.0034],\n",
       "        [0.0045],\n",
       "        [0.0046],\n",
       "        [0.0035],\n",
       "        [0.0018],\n",
       "        [0.0033],\n",
       "        [0.0025],\n",
       "        [0.0025],\n",
       "        [0.0013],\n",
       "        [0.0054],\n",
       "        [0.0024],\n",
       "        [0.0039],\n",
       "        [0.0034],\n",
       "        [0.0055],\n",
       "        [0.0027],\n",
       "        [0.0048],\n",
       "        [0.0024],\n",
       "        [0.0040],\n",
       "        [0.0032],\n",
       "        [0.0034],\n",
       "        [0.0032],\n",
       "        [0.0022],\n",
       "        [0.0030],\n",
       "        [0.0024],\n",
       "        [0.0024],\n",
       "        [0.0029],\n",
       "        [0.0020],\n",
       "        [0.0044],\n",
       "        [0.0041],\n",
       "        [0.0030],\n",
       "        [0.0018],\n",
       "        [0.0030],\n",
       "        [0.0037],\n",
       "        [0.0041],\n",
       "        [0.0098],\n",
       "        [0.0044],\n",
       "        [0.0068],\n",
       "        [0.0036],\n",
       "        [0.0021],\n",
       "        [0.0051],\n",
       "        [0.0033],\n",
       "        [0.0029],\n",
       "        [0.0028],\n",
       "        [0.0038],\n",
       "        [0.0025],\n",
       "        [0.0045],\n",
       "        [0.0032],\n",
       "        [0.0020],\n",
       "        [0.0035],\n",
       "        [0.0070],\n",
       "        [0.0031],\n",
       "        [0.0018],\n",
       "        [0.0055],\n",
       "        [0.0032],\n",
       "        [0.0038],\n",
       "        [0.0029],\n",
       "        [0.0030],\n",
       "        [0.0026],\n",
       "        [0.0021],\n",
       "        [0.0048],\n",
       "        [0.0029],\n",
       "        [0.0023],\n",
       "        [0.0024],\n",
       "        [0.0049],\n",
       "        [0.0047],\n",
       "        [0.0032],\n",
       "        [0.0029],\n",
       "        [0.0028],\n",
       "        [0.0062],\n",
       "        [0.0041],\n",
       "        [0.0024],\n",
       "        [0.0027],\n",
       "        [0.0048],\n",
       "        [0.0034],\n",
       "        [0.0022],\n",
       "        [0.0018],\n",
       "        [0.0062],\n",
       "        [0.0023],\n",
       "        [0.0019],\n",
       "        [0.0044],\n",
       "        [0.0026],\n",
       "        [0.0024],\n",
       "        [0.0031],\n",
       "        [0.0027],\n",
       "        [0.0034],\n",
       "        [0.0025],\n",
       "        [0.0043],\n",
       "        [0.0039],\n",
       "        [0.0027],\n",
       "        [0.0026],\n",
       "        [0.0029],\n",
       "        [0.0030],\n",
       "        [0.0044],\n",
       "        [0.0047],\n",
       "        [0.0027],\n",
       "        [0.0059],\n",
       "        [0.0031],\n",
       "        [0.0021],\n",
       "        [0.0042],\n",
       "        [0.0026],\n",
       "        [0.0045],\n",
       "        [0.0019],\n",
       "        [0.0026],\n",
       "        [0.0033],\n",
       "        [0.0031],\n",
       "        [0.0023],\n",
       "        [0.0022],\n",
       "        [0.0031],\n",
       "        [0.0039],\n",
       "        [0.0032],\n",
       "        [0.0037],\n",
       "        [0.0035],\n",
       "        [0.0019],\n",
       "        [0.0043],\n",
       "        [0.0036],\n",
       "        [0.0026],\n",
       "        [0.0031],\n",
       "        [0.0019],\n",
       "        [0.0028],\n",
       "        [0.0025],\n",
       "        [0.0034],\n",
       "        [0.0043],\n",
       "        [0.0053],\n",
       "        [0.0024],\n",
       "        [0.0026],\n",
       "        [0.0041],\n",
       "        [0.0034],\n",
       "        [0.0032],\n",
       "        [0.0038],\n",
       "        [0.0028],\n",
       "        [0.0046],\n",
       "        [0.0080],\n",
       "        [0.0033],\n",
       "        [0.0034],\n",
       "        [0.0039],\n",
       "        [0.0023],\n",
       "        [0.0067],\n",
       "        [0.0029],\n",
       "        [0.0022],\n",
       "        [0.0039],\n",
       "        [0.0022],\n",
       "        [0.0024],\n",
       "        [0.0022],\n",
       "        [0.0034],\n",
       "        [0.0028],\n",
       "        [0.0022],\n",
       "        [0.0053],\n",
       "        [0.0026],\n",
       "        [0.0039],\n",
       "        [0.0035],\n",
       "        [0.0018],\n",
       "        [0.0013],\n",
       "        [0.0030],\n",
       "        [0.0033],\n",
       "        [0.0054],\n",
       "        [0.0047],\n",
       "        [0.0018],\n",
       "        [0.0018],\n",
       "        [0.0040],\n",
       "        [0.0049],\n",
       "        [0.0069],\n",
       "        [0.0027]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_mask[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0023],\n",
       "        [0.0055],\n",
       "        [0.0030],\n",
       "        [0.0020],\n",
       "        [0.0026],\n",
       "        [0.0023],\n",
       "        [0.0021],\n",
       "        [0.0033],\n",
       "        [0.0027],\n",
       "        [0.0027],\n",
       "        [0.0040],\n",
       "        [0.0027],\n",
       "        [0.0026],\n",
       "        [0.0014],\n",
       "        [0.0046],\n",
       "        [0.0044],\n",
       "        [0.0028],\n",
       "        [0.0040],\n",
       "        [0.0028],\n",
       "        [0.0022],\n",
       "        [0.0026],\n",
       "        [0.0026],\n",
       "        [0.0026],\n",
       "        [0.0049],\n",
       "        [0.0023],\n",
       "        [0.0018],\n",
       "        [0.0024],\n",
       "        [0.0023],\n",
       "        [0.0037],\n",
       "        [0.0032],\n",
       "        [0.0039],\n",
       "        [0.0029],\n",
       "        [0.0016],\n",
       "        [0.0032],\n",
       "        [0.0032],\n",
       "        [0.0035],\n",
       "        [0.0048],\n",
       "        [0.0048],\n",
       "        [0.0032],\n",
       "        [0.0019],\n",
       "        [0.0042],\n",
       "        [0.0030],\n",
       "        [0.0025],\n",
       "        [0.0019],\n",
       "        [0.0026],\n",
       "        [0.0029],\n",
       "        [0.0020],\n",
       "        [0.0019],\n",
       "        [0.0035],\n",
       "        [0.0043],\n",
       "        [0.0036],\n",
       "        [0.0022],\n",
       "        [0.0019],\n",
       "        [0.0031],\n",
       "        [0.0019],\n",
       "        [0.0029],\n",
       "        [0.0072],\n",
       "        [0.0027],\n",
       "        [0.0032],\n",
       "        [0.0029],\n",
       "        [0.0046],\n",
       "        [0.0032],\n",
       "        [0.0055],\n",
       "        [0.0039],\n",
       "        [0.0022],\n",
       "        [0.0025],\n",
       "        [0.0017],\n",
       "        [0.0039],\n",
       "        [0.0025],\n",
       "        [0.0042],\n",
       "        [0.0019],\n",
       "        [0.0024],\n",
       "        [0.0042],\n",
       "        [0.0018],\n",
       "        [0.0042],\n",
       "        [0.0030],\n",
       "        [0.0015],\n",
       "        [0.0025],\n",
       "        [0.0023],\n",
       "        [0.0035],\n",
       "        [0.0036],\n",
       "        [0.0023],\n",
       "        [0.0029],\n",
       "        [0.0020],\n",
       "        [0.0029],\n",
       "        [0.0018],\n",
       "        [0.0028],\n",
       "        [0.0032],\n",
       "        [0.0023],\n",
       "        [0.0018],\n",
       "        [0.0044],\n",
       "        [0.0030],\n",
       "        [0.0053],\n",
       "        [0.0023],\n",
       "        [0.0021],\n",
       "        [0.0043],\n",
       "        [0.0061],\n",
       "        [0.0078],\n",
       "        [0.0039],\n",
       "        [0.0043],\n",
       "        [0.0020],\n",
       "        [0.0022],\n",
       "        [0.0032],\n",
       "        [0.0026],\n",
       "        [0.0036],\n",
       "        [0.0030],\n",
       "        [0.0045],\n",
       "        [0.0030],\n",
       "        [0.0030],\n",
       "        [0.0023],\n",
       "        [0.0030],\n",
       "        [0.0042],\n",
       "        [0.0015],\n",
       "        [0.0043],\n",
       "        [0.0035],\n",
       "        [0.0022],\n",
       "        [0.0034],\n",
       "        [0.0048],\n",
       "        [0.0026],\n",
       "        [0.0054],\n",
       "        [0.0059],\n",
       "        [0.0053],\n",
       "        [0.0045],\n",
       "        [0.0055],\n",
       "        [0.0023],\n",
       "        [0.0049],\n",
       "        [0.0034],\n",
       "        [0.0037],\n",
       "        [0.0027],\n",
       "        [0.0040],\n",
       "        [0.0030],\n",
       "        [0.0019],\n",
       "        [0.0027],\n",
       "        [0.0055],\n",
       "        [0.0035],\n",
       "        [0.0031],\n",
       "        [0.0022],\n",
       "        [0.0042],\n",
       "        [0.0016],\n",
       "        [0.0025],\n",
       "        [0.0025],\n",
       "        [0.0029],\n",
       "        [0.0045],\n",
       "        [0.0026],\n",
       "        [0.0019],\n",
       "        [0.0024],\n",
       "        [0.0026],\n",
       "        [0.0030],\n",
       "        [0.0054],\n",
       "        [0.0043],\n",
       "        [0.0040],\n",
       "        [0.0044],\n",
       "        [0.0017],\n",
       "        [0.0037],\n",
       "        [0.0018],\n",
       "        [0.0022],\n",
       "        [0.0056],\n",
       "        [0.0049],\n",
       "        [0.0037],\n",
       "        [0.0029],\n",
       "        [0.0020],\n",
       "        [0.0033],\n",
       "        [0.0042],\n",
       "        [0.0031],\n",
       "        [0.0029],\n",
       "        [0.0046],\n",
       "        [0.0021],\n",
       "        [0.0052],\n",
       "        [0.0053],\n",
       "        [0.0018],\n",
       "        [0.0019],\n",
       "        [0.0022],\n",
       "        [0.0043],\n",
       "        [0.0028],\n",
       "        [0.0033],\n",
       "        [0.0041],\n",
       "        [0.0023],\n",
       "        [0.0034],\n",
       "        [0.0025],\n",
       "        [0.0032],\n",
       "        [0.0022],\n",
       "        [0.0051],\n",
       "        [0.0040],\n",
       "        [0.0028],\n",
       "        [0.0034],\n",
       "        [0.0027],\n",
       "        [0.0055],\n",
       "        [0.0022],\n",
       "        [0.0016],\n",
       "        [0.0038],\n",
       "        [0.0020],\n",
       "        [0.0038],\n",
       "        [0.0034],\n",
       "        [0.0052],\n",
       "        [0.0027],\n",
       "        [0.0059],\n",
       "        [0.0010],\n",
       "        [0.0040],\n",
       "        [0.0020],\n",
       "        [0.0034],\n",
       "        [0.0057],\n",
       "        [0.0021],\n",
       "        [0.0037],\n",
       "        [0.0027],\n",
       "        [0.0030],\n",
       "        [0.0036],\n",
       "        [0.0035],\n",
       "        [0.0023],\n",
       "        [0.0028],\n",
       "        [0.0025],\n",
       "        [0.0026],\n",
       "        [0.0036],\n",
       "        [0.0026],\n",
       "        [0.0050],\n",
       "        [0.0025],\n",
       "        [0.0034],\n",
       "        [0.0023],\n",
       "        [0.0022],\n",
       "        [0.0034],\n",
       "        [0.0051],\n",
       "        [0.0023],\n",
       "        [0.0068],\n",
       "        [0.0026],\n",
       "        [0.0041],\n",
       "        [0.0043],\n",
       "        [0.0038],\n",
       "        [0.0041],\n",
       "        [0.0034],\n",
       "        [0.0042],\n",
       "        [0.0027],\n",
       "        [0.0059],\n",
       "        [0.0026],\n",
       "        [0.0024],\n",
       "        [0.0076],\n",
       "        [0.0031],\n",
       "        [0.0022],\n",
       "        [0.0034],\n",
       "        [0.0035],\n",
       "        [0.0023],\n",
       "        [0.0030],\n",
       "        [0.0022],\n",
       "        [0.0028],\n",
       "        [0.0041],\n",
       "        [0.0057],\n",
       "        [0.0051],\n",
       "        [0.0021],\n",
       "        [0.0042],\n",
       "        [0.0045],\n",
       "        [0.0025],\n",
       "        [0.0026],\n",
       "        [0.0030],\n",
       "        [0.0034],\n",
       "        [0.0051],\n",
       "        [0.0024],\n",
       "        [0.0037],\n",
       "        [0.0026],\n",
       "        [0.0030],\n",
       "        [0.0038],\n",
       "        [0.0033],\n",
       "        [0.0023],\n",
       "        [0.0024],\n",
       "        [0.0039],\n",
       "        [0.0050],\n",
       "        [0.0042],\n",
       "        [0.0034],\n",
       "        [0.0041],\n",
       "        [0.0033],\n",
       "        [0.0024],\n",
       "        [0.0021],\n",
       "        [0.0044],\n",
       "        [0.0031],\n",
       "        [0.0031],\n",
       "        [0.0032],\n",
       "        [0.0052],\n",
       "        [0.0027],\n",
       "        [0.0037],\n",
       "        [0.0053],\n",
       "        [0.0025],\n",
       "        [0.0050],\n",
       "        [0.0035],\n",
       "        [0.0052],\n",
       "        [0.0020],\n",
       "        [0.0039],\n",
       "        [0.0055],\n",
       "        [0.0029],\n",
       "        [0.0039],\n",
       "        [0.0022],\n",
       "        [0.0044],\n",
       "        [0.0051],\n",
       "        [0.0080],\n",
       "        [0.0059],\n",
       "        [0.0034],\n",
       "        [0.0013],\n",
       "        [0.0033],\n",
       "        [0.0020],\n",
       "        [0.0042],\n",
       "        [0.0025],\n",
       "        [0.0041],\n",
       "        [0.0032]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50, 50])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.train(False)\n",
    "score_mask = model(user_id, history_title, his_mask, impressions_title, impressions_mask)\n",
    "score = model(user_id, history_title, his_mask, impressions_title, impressions_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
