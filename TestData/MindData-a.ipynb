{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "\n",
    "from General.Utils import ValidateModel\n",
    "from DataIterator import NewsDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from TestData.MindDependencies.Metrics import cal_metric\n",
    "\n",
    "import torch as th\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "# Import Hparam\n",
    "with open('Data/MINDdemo_utils/lstur.yaml','r') as stream:\n",
    "    hparams = yaml.safe_load(stream)\n",
    "\n",
    "# Import word_vec\n",
    "word_embedding = np.load('Data/MINDdemo_utils/embedding_all.npy')\n",
    "word_embedding = word_embedding.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Device\n",
    "device = 'cuda' if th.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Define Data, Dataset and DataLoaders\n",
    "train_behaviors_file = 'Data/MINDdemo_train/behaviors.tsv'\n",
    "train_news_file = 'Data/MINDdemo_train/news.tsv'\n",
    "word_dict_file = 'Data/MINDdemo_utils/word_dict_all.pkl'\n",
    "user_dict_file = 'Data/MINDdemo_utils/uid2index.pkl'\n",
    "\n",
    "valid_behaviors_file = 'Data/MINDdemo_dev/behaviors.tsv'\n",
    "valid_news_file = 'Data/MINDdemo_dev/news.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/magnusharder/Documents/UNI-DTU/6. Semester/Bachelor Projekt/News-Recommendations/DataIterator.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.user_data['history_length'][self.user_data['history_length'] > 50] = 50\n",
      "/Users/magnusharder/Documents/UNI-DTU/6. Semester/Bachelor Projekt/News-Recommendations/DataIterator.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.user_data['history_length'][self.user_data['history_length'] > 50] = 50\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open (\"Data/MINDdemo_utils/word_dict.pkl\", \"rb\") as f:\n",
    "    word_dict = pickle.load(f)\n",
    "with open (\"Data/MINDdemo_utils/uid2index.pkl\", \"rb\") as f:\n",
    "    uid2index = pickle.load(f)\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class HyperParams:\n",
    "    batch_size: int\n",
    "    title_size: int\n",
    "    his_size: int\n",
    "    wordDict_file: str\n",
    "    userDict_file: str\n",
    "\n",
    "hparamsdata = HyperParams(\n",
    "    batch_size=32,\n",
    "    title_size=20,\n",
    "    his_size=50,\n",
    "    wordDict_file=word_dict_file,\n",
    "    userDict_file=user_dict_file,\n",
    ")\n",
    "\n",
    "TrainData = NewsDataset(train_behaviors_file, train_news_file, word_dict_file, userid_dict=uid2index, train=True)\n",
    "TestData = NewsDataset(valid_behaviors_file, valid_news_file, word_dict_file, userid_dict=uid2index, train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/magnusharder/Documents/UNI-DTU/6. Semester/Bachelor Projekt/News-Recommendations/TestData/LSTURMind_a.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.word_embedding = nn.Embedding.from_pretrained(th.tensor(word_vectors,dtype=th.float32), freeze=False, padding_idx=0)\n"
     ]
    }
   ],
   "source": [
    "from TestData.LSTURMind_a import LSTURini\n",
    "\n",
    "# Set Model Architecture\n",
    "LSTUR_con_module = LSTURini(\n",
    "    attention_dim = hparams['model']['attention_hidden_dim'],\n",
    "    word_emb_dim = hparams['model']['word_emb_dim'],\n",
    "    dropout = hparams['model']['dropout'],\n",
    "    filter_num = hparams['model']['filter_num'],\n",
    "    windows_size = hparams['model']['window_size'],\n",
    "    gru_unit = hparams['model']['gru_unit'],\n",
    "    user_size = uid2index.__len__() + 1,\n",
    "    word_vectors = th.from_numpy(word_embedding).to(device),\n",
    "    device = device\n",
    ")\n",
    "\n",
    "model = LSTUR_con_module.to(device)\n",
    "\n",
    "# Define Optimizer\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "loss_fn = th.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 1889/7335 [01:54<05:30, 16.46it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m tqdm(vali_batch_loader):\n\u001b[1;32m     11\u001b[0m     user_id, history_title, history_abstract, history_length, impressions_title, impressions_abstract, impressions_length, labels, n_positive \u001b[39m=\u001b[39m batch\n\u001b[0;32m---> 13\u001b[0m     Scores \u001b[39m=\u001b[39m model(user_id, history_title, history_length, impressions_title)\n\u001b[1;32m     15\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(Scores, labels)\n\u001b[1;32m     16\u001b[0m     loss_vali\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/Documents/UNI-DTU/6. Semester/Bachelor Projekt/News-Recommendations/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/UNI-DTU/6. Semester/Bachelor Projekt/News-Recommendations/TestData/LSTURMind_a.py:181\u001b[0m, in \u001b[0;36mLSTURini.forward\u001b[0;34m(self, user_id, history_title, history_length, impressions_title)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, user_id, history_title, history_length, impressions_title):\n\u001b[1;32m    179\u001b[0m     \n\u001b[1;32m    180\u001b[0m     \u001b[39m# User embedding\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m     Users \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mUserEncoder(user_id, history_title, history_length)\n\u001b[1;32m    184\u001b[0m     b, n, t \u001b[39m=\u001b[39m impressions_title\u001b[39m.\u001b[39mshape\n\u001b[1;32m    185\u001b[0m     Candidates \u001b[39m=\u001b[39m  th\u001b[39m.\u001b[39mzeros(b,n,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnews_size,device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/Documents/UNI-DTU/6. Semester/Bachelor Projekt/News-Recommendations/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/UNI-DTU/6. Semester/Bachelor Projekt/News-Recommendations/TestData/LSTURMind_a.py:152\u001b[0m, in \u001b[0;36mUserEncoder.forward\u001b[0;34m(self, user_id, history_title, history_length)\u001b[0m\n\u001b[1;32m    149\u001b[0m user_embed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mUserEmbedding(user_id)\n\u001b[1;32m    151\u001b[0m \u001b[39m# Pack the news embedding\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m packed_news \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mrnn\u001b[39m.\u001b[39;49mpack_padded_sequence(news_embed, history_length\u001b[39m.\u001b[39;49mcpu(), batch_first\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, enforce_sorted\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    153\u001b[0m output,hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgru(packed_news, user_embed\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m))\n\u001b[1;32m    155\u001b[0m \u001b[39m# Batch, User\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/UNI-DTU/6. Semester/Bachelor Projekt/News-Recommendations/.venv/lib/python3.9/site-packages/torch/nn/utils/rnn.py:256\u001b[0m, in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    254\u001b[0m     sorted_indices \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 256\u001b[0m     lengths, sorted_indices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49msort(lengths, descending\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    257\u001b[0m     sorted_indices \u001b[39m=\u001b[39m sorted_indices\u001b[39m.\u001b[39mto(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    258\u001b[0m     batch_dim \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m batch_first \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "with th.no_grad():\n",
    "    model.eval()\n",
    "    model.train(False)\n",
    "    labels_all = []\n",
    "    preds_all = []\n",
    "    loss_vali = []\n",
    "\n",
    "    vali_batch_loader = DataLoader(TestData, batch_size=1, shuffle=False)\n",
    "\n",
    "    for batch in tqdm(vali_batch_loader):\n",
    "        user_id, history_title, history_abstract, history_length, impressions_title, impressions_abstract, impressions_length, labels, n_positive = batch\n",
    "\n",
    "        Scores = model(user_id, history_title, history_length, impressions_title)\n",
    "\n",
    "        loss = loss_fn(Scores, labels)\n",
    "        loss_vali.append(loss.item())\n",
    "    \n",
    "        labels_all.append(labels.squeeze(0).numpy())\n",
    "        preds_all.append(Scores.squeeze(0).detach().numpy())\n",
    "\n",
    "        \n",
    "    \n",
    "    Pre_training = cal_metric(labels_all,preds_all,metrics=['group_auc', 'mean_mrr', 'ndcg@5;10'])\n",
    "    Pre_training['loss'] = np.mean(loss_vali)\n",
    "    \n",
    "    print(Pre_training)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m NDCG5 \u001b[39m=\u001b[39m [Pre_training[\u001b[39m'\u001b[39m\u001b[39mndcg@5\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m      5\u001b[0m NDCG10 \u001b[39m=\u001b[39m [Pre_training[\u001b[39m'\u001b[39m\u001b[39mndcg@10\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m----> 6\u001b[0m loss_vali \u001b[39m=\u001b[39m [Pre_training[\u001b[39m'\u001b[39;49m\u001b[39mloss\u001b[39;49m\u001b[39m'\u001b[39;49m]]\n\u001b[1;32m      7\u001b[0m Loss_training \u001b[39m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(hparams[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m'\u001b[39m]):\n",
      "\u001b[0;31mKeyError\u001b[0m: 'loss'"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "AUC = [Pre_training['group_auc']]\n",
    "MRR = [Pre_training['mean_mrr']]\n",
    "NDCG5 = [Pre_training['ndcg@5']]\n",
    "NDCG10 = [Pre_training['ndcg@10']]\n",
    "loss_vali = [Pre_training['loss']]\n",
    "Loss_training = []\n",
    "\n",
    "\n",
    "for epoch in range(hparams['train']['epochs']):\n",
    "    model.train(True)\n",
    "\n",
    "    train_data_loader = DataLoader(TrainData, batch_size=hparamsdata.batch_size, shuffle=True)\n",
    "\n",
    "    for batch in tqdm(train_data_loader):\n",
    "\n",
    "        user_id, history_title, history_abstract, history_length, impressions_title, impressions_abstract, impressions_length, labels, n_positive = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        Scores = model(user_id, history_title, history_length, impressions_title)\n",
    "\n",
    "        loss = loss_fn(Scores,labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        Loss_training.append(loss.item())\n",
    "    \n",
    "    with th.no_grad():\n",
    "        model.eval()\n",
    "        model.train(False)\n",
    "        labels_all = []\n",
    "        preds_all = []\n",
    "        loss_vali = []\n",
    "\n",
    "        vali_batch_loader = DataLoader(TestData, batch_size=1, shuffle=False)\n",
    "\n",
    "        for batch in tqdm(vali_batch_loader):\n",
    "            user_id, history_title, history_abstract, history_length, impressions_title, impressions_abstract, impressions_length, labels, n_positive = batch\n",
    "\n",
    "            Scores = model(user_id, history_title, history_length, impressions_title)\n",
    "\n",
    "            loss = loss_fn(Scores, labels)\n",
    "            loss_vali.append(loss.item())\n",
    "\n",
    "            labels_all.append(labels.squeeze(0).numpy())\n",
    "            preds_all.append(Scores.squeeze(0).detach().numpy())\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "        result = cal_metric(labels_all,preds_all,metrics=['group_auc', 'mean_mrr', 'ndcg@5;10'])\n",
    "        result['loss'] = np.mean(loss_vali)\n",
    "\n",
    "        AUC.append(result['group_auc'])\n",
    "        MRR.append(result['mean_mrr'])\n",
    "        NDCG5.append(result['ndcg@5'])\n",
    "        NDCG10.append(result['ndcg@510'])\n",
    "        loss_vali.append(result['loss'])\n",
    "    \n",
    "    print(f'Memory: {th.cuda.memory_reserved()/(10**9)} GB')\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# Saving Training Logs\n",
    "with open('MindTrainMasking.pkl', 'wb') as f:\n",
    "    pickle.dump([], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
