{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Description: Load tsv file\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "# Load tsv file\n",
    "News_vali = pd.read_csv('MINDsmall_dev/news.tsv', sep='\\t', header=None)\n",
    "News_vali.columns = ['news_id', 'category', 'subcategory', 'title', 'abstract', 'url', 'title_entities', 'abstract_entities']\n",
    "\n",
    "User_vali = pd.read_csv('MINDsmall_dev/behaviors.tsv', sep='\\t', header=None)\n",
    "User_vali.columns = ['impression_id', 'user_id', 'time', 'history', 'impressions']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data contains 17 topics and 264 subtopics\n"
     ]
    }
   ],
   "source": [
    "# Description: Load tsv file\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Load tsv file\n",
    "News = pd.read_csv('MINDsmall_train/news.tsv', sep='\\t', header=None)\n",
    "News.columns = ['news_id', 'category', 'subcategory', 'title', 'abstract', 'url', 'title_entities', 'abstract_entities']\n",
    "News_vali = pd.read_csv('MINDsmall_dev/news.tsv', sep='\\t', header=None)\n",
    "News_vali.columns = ['news_id', 'category', 'subcategory', 'title', 'abstract', 'url', 'title_entities', 'abstract_entities']\n",
    "\n",
    "News_con = pd.concat([News, News_vali], ignore_index=True)\n",
    "\n",
    "\n",
    "UserData = pd.read_csv('MINDsmall_train/behaviors.tsv', sep='\\t', header=None)\n",
    "UserData.columns = ['impression_id', 'user_id', 'time', 'history', 'impressions']\n",
    "\n",
    "UserData = UserData.dropna()\n",
    "\n",
    "topic_size = News['category'].nunique()\n",
    "subtopic_size = News['subcategory'].nunique()\n",
    "\n",
    "print(f\"Data contains {topic_size} topics and {subtopic_size} subtopics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "torch_tokenizer = get_tokenizer('basic_english')\n",
    "mind_tokenizer = RegexpTokenizer(r\"\\w+|[.,!?;'|]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 The Brands Queen Elizabeth, Prince Charles, and Prince Philip Swear By\n",
      "Torch Tokenizer: ['the', 'brands', 'queen', 'elizabeth', ',', 'prince', 'charles', ',', 'and', 'prince', 'philip', 'swear', 'by']\n",
      "Mind Tokenizer: ['the', 'brands', 'queen', 'elizabeth', ',', 'prince', 'charles', ',', 'and', 'prince', 'philip', 'swear', 'by']\n",
      "\n",
      "2 50 Worst Habits For Belly Fat\n",
      "Torch Tokenizer: ['50', 'worst', 'habits', 'for', 'belly', 'fat']\n",
      "Mind Tokenizer: ['50', 'worst', 'habits', 'for', 'belly', 'fat']\n",
      "\n",
      "3 The Cost of Trump's Aid Freeze in the Trenches of Ukraine's War\n",
      "Torch Tokenizer: ['the', 'cost', 'of', 'trump', \"'\", 's', 'aid', 'freeze', 'in', 'the', 'trenches', 'of', 'ukraine', \"'\", 's', 'war']\n",
      "Mind Tokenizer: ['the', 'cost', 'of', 'trump', \"'\", 's', 'aid', 'freeze', 'in', 'the', 'trenches', 'of', 'ukraine', \"'\", 's', 'war']\n",
      "\n",
      "4 I Was An NBA Wife. Here's How It Affected My Mental Health.\n",
      "Torch Tokenizer: ['i', 'was', 'an', 'nba', 'wife', '.', 'here', \"'\", 's', 'how', 'it', 'affected', 'my', 'mental', 'health', '.']\n",
      "Mind Tokenizer: ['i', 'was', 'an', 'nba', 'wife', '.', 'here', \"'\", 's', 'how', 'it', 'affected', 'my', 'mental', 'health', '.']\n",
      "\n",
      "5 How to Get Rid of Skin Tags, According to a Dermatologist\n",
      "Torch Tokenizer: ['how', 'to', 'get', 'rid', 'of', 'skin', 'tags', ',', 'according', 'to', 'a', 'dermatologist']\n",
      "Mind Tokenizer: ['how', 'to', 'get', 'rid', 'of', 'skin', 'tags', ',', 'according', 'to', 'a', 'dermatologist']\n",
      "\n",
      "6 Should NFL be able to fine players for criticizing officiating?\n",
      "Torch Tokenizer: ['should', 'nfl', 'be', 'able', 'to', 'fine', 'players', 'for', 'criticizing', 'officiating', '?']\n",
      "Mind Tokenizer: ['should', 'nfl', 'be', 'able', 'to', 'fine', 'players', 'for', 'criticizing', 'officiating', '?']\n",
      "\n",
      "7 It's been Orlando's hottest October ever so far, but cooler temperatures on the way\n",
      "Torch Tokenizer: ['it', \"'\", 's', 'been', 'orlando', \"'\", 's', 'hottest', 'october', 'ever', 'so', 'far', ',', 'but', 'cooler', 'temperatures', 'on', 'the', 'way']\n",
      "Mind Tokenizer: ['it', \"'\", 's', 'been', 'orlando', \"'\", 's', 'hottest', 'october', 'ever', 'so', 'far', ',', 'but', 'cooler', 'temperatures', 'on', 'the', 'way']\n",
      "\n",
      "8 Chile: Three die in supermarket fire amid protests\n",
      "Torch Tokenizer: ['chile', 'three', 'die', 'in', 'supermarket', 'fire', 'amid', 'protests']\n",
      "Mind Tokenizer: ['chile', 'three', 'die', 'in', 'supermarket', 'fire', 'amid', 'protests']\n",
      "\n",
      "9 Best PS5 games: top PlayStation 5 titles to look forward to\n",
      "Torch Tokenizer: ['best', 'ps5', 'games', 'top', 'playstation', '5', 'titles', 'to', 'look', 'forward', 'to']\n",
      "Mind Tokenizer: ['best', 'ps5', 'games', 'top', 'playstation', '5', 'titles', 'to', 'look', 'forward', 'to']\n",
      "\n",
      "10 How to report weather-related closings, delays\n",
      "Torch Tokenizer: ['how', 'to', 'report', 'weather-related', 'closings', ',', 'delays']\n",
      "Mind Tokenizer: ['how', 'to', 'report', 'weather', 'related', 'closings', ',', 'delays']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "\n",
    "    sentence = News['title'][i]\n",
    "    print(i+1,sentence)\n",
    "\n",
    "    print(f\"Torch Tokenizer: {torch_tokenizer(sentence)}\")\n",
    "\n",
    "    print(f\"Mind Tokenizer: {mind_tokenizer.tokenize(sentence.lower())}\")\n",
    "\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2161e111f783a6322a6ae262a47844d9386d7dfb61a436620c434d93864cb0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
